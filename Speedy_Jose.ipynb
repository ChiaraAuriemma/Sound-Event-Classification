{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRSb4e0MBD0d"
      },
      "source": [
        "**Lab 4** for the course of *Selected Topics in Music and Acoustic Engineering* :\n",
        "\n",
        "***Machine Learning for Audio and Acoustic Engineering***\n",
        "---\n",
        "\n",
        "Implementation on PyTorch\n",
        "\n",
        "\n",
        "# **Lab 4: Neural Networks (II)**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8kmdIHGSOO_"
      },
      "source": [
        "In this lab we will continue exploring different types of deep architectures for audio processing, and we will pay special attention to system evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6U5xvhLUsTJ"
      },
      "outputs": [],
      "source": [
        "# As always, we import the relevant packages\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HDemucs(\n",
              "  (freq_encoder): ModuleList(\n",
              "    (0): _HEncLayer(\n",
              "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): _HEncLayer(\n",
              "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): _HEncLayer(\n",
              "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): _HEncLayer(\n",
              "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): _HEncLayer(\n",
              "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): _HEncLayer(\n",
              "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): _BLSTM(\n",
              "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
              "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
              "            )\n",
              "            (4): _LocalState(\n",
              "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
              "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
              "            )\n",
              "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
              "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
              "            (7): GLU(dim=1)\n",
              "            (8): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (freq_decoder): ModuleList(\n",
              "    (0): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
              "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
              "    )\n",
              "    (1): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
              "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
              "    )\n",
              "    (2): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (3): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (4): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (5): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "  )\n",
              "  (time_encoder): ModuleList(\n",
              "    (0): _HEncLayer(\n",
              "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): _HEncLayer(\n",
              "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): _HEncLayer(\n",
              "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): _HEncLayer(\n",
              "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): Identity()\n",
              "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
              "      (norm2): Identity()\n",
              "      (dconv): _DConv(\n",
              "        (layers): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
              "            (2): GELU(approximate='none')\n",
              "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
              "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
              "            (5): GLU(dim=1)\n",
              "            (6): _LayerScale()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): _HEncLayer(\n",
              "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
              "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
              "      (rewrite): Identity()\n",
              "      (norm2): Identity()\n",
              "      (dconv): Identity()\n",
              "    )\n",
              "  )\n",
              "  (time_decoder): ModuleList(\n",
              "    (0): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
              "      (rewrite): Identity()\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (1): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (2): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (3): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "    (4): _HDecLayer(\n",
              "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
              "      (norm2): Identity()\n",
              "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (norm1): Identity()\n",
              "    )\n",
              "  )\n",
              "  (freq_emb): _ScaledEmbedding(\n",
              "    (embedding): Embedding(512, 48)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cpu_device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Device Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhMvCfOxT1vq"
      },
      "source": [
        "### **Exercise 1**: Data Preparation I\n",
        "\n",
        "We will continue working with the ESC-50 dataset. Download it to your notebook following the same steps as in Lab 2 and Lab 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yf9PY8gUD08",
        "outputId": "440731d3-036a-4df5-b6d3-e03eadc561e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "unzip:  cannot find or open master.zip, master.zip.zip or master.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/karolpiczak/ESC-50/archive/master.zip\n",
        "!unzip master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6bPjK6OVeNs"
      },
      "source": [
        "Create a list containing the audio files and another one with the corresponding labels (as in Lab 3):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DyYxVH6VUO4W"
      },
      "outputs": [],
      "source": [
        "fn_csv = '/Users/filippo/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Corsi/Selected Topics in Music and Acoustic Engineering 👨🏻‍🏫/Codes STMAE/ESC-50-master/meta/esc50.csv'\n",
        "\n",
        "files = []  # File list\n",
        "labels = []  # Class list\n",
        "\n",
        "df = pd.read_csv(fn_csv)\n",
        "\n",
        "#unique class labels\n",
        "unique_classes = df['category'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATIutRkfUo-k"
      },
      "source": [
        "Instead of working with 50 classes, we limit our dataset to only 10 classes. Filter you two files (the one with file paths and the one with labels) to contain only those belonging to classes [0-9]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMwVmhVqUdCa",
        "outputId": "687473f9-12cd-4bb3-dee9-01c0972c6ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 classes: ['dog' 'chirping_birds' 'vacuum_cleaner' 'thunderstorm' 'door_wood_knock'\n",
            " 'can_opening' 'crow' 'clapping' 'fireworks' 'chainsaw']\n"
          ]
        }
      ],
      "source": [
        "# 10 first classes\n",
        "our_classes = unique_classes[0:10]\n",
        "print(\"First 10 classes:\", our_classes)\n",
        "\n",
        "# Filter the dataset to only include the selected classes\n",
        "filtered_df = df.query('category in @our_classes')\n",
        "\n",
        "files = filtered_df['filename'].values\n",
        "labels = filtered_df['category'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvbyUM8nU_fv"
      },
      "source": [
        "We load the signals and get the Mel spectrogram for each signal. Create a list called \"signals\" storing the raw waveforms of each file in your list and another one called \"melspecs\" that stores the Mel spectrogram for each signal.\n",
        "\n",
        "Note: use the default parameters for librosa.load (resample to 22050Hz) and librosa.feature.melspectrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743iyIr3U7wy",
        "outputId": "b974d86c-3734-47f4-e32d-8f9dbc3bb383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22050\n"
          ]
        }
      ],
      "source": [
        "path = '/Users/filippo/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Corsi/Selected Topics in Music and Acoustic Engineering 👨🏻‍🏫/Codes STMAE/ESC-50-master/audio/'\n",
        "signals = list(librosa.load(path + file)[0] for file in files)\n",
        "\n",
        "signal1, sr = librosa.load(path + '1-100032-A-0.wav')\n",
        "print(sr)\n",
        "\n",
        "melspecs = list(librosa.feature.melspectrogram(y=signal, sr=sr) for signal in signals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASOMPEK5XI8-"
      },
      "source": [
        "### **Exercise 2**: Data preparation II\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j11Q0Q9lXpqu"
      },
      "source": [
        "Convert your \"melspecs\" and \"labels\" list to numpy arrays, called \"Xdata\" and \"Ydata\".\n",
        "Check that the result has size (400, 128, 216) for Xdata and (400,) for Ydata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6AFgQCCXzdk",
        "outputId": "c33cd637-aea0-4525-9697-d88ed3d38f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xdata shape: (400, 128, 216) \n",
            "Yata shape: (400,)\n"
          ]
        }
      ],
      "source": [
        "Xdata = np.asarray(melspecs)\n",
        "\n",
        "# Transform the labels to numbers\n",
        "label_mapping = {label: idx for idx, label in enumerate(dict.fromkeys(labels))}\n",
        "numerical_labels = np.array([label_mapping[label] for label in labels])\n",
        "\n",
        "Ydata = np.asarray(numerical_labels)\n",
        "\n",
        "print('Xdata shape: {} \\nYata shape: {}'.format(Xdata.shape, Ydata.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJGWNAGrSwYU"
      },
      "source": [
        "Check that Ydata is balanced by plotting the histogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "CIJcy2KSSwYU",
        "outputId": "bde5958d-5c2a-40d0-b835-aeaf2ffb6de2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.title(\"Number of samples per class\")\n",
        "plt.hist(labels, bins=10,edgecolor='black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvB-50z4tFqP"
      },
      "source": [
        "As we can see from the histogram, we have exactly the same number of element for each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgJiKJgoYGtJ"
      },
      "source": [
        "Split your dataset into 3 partitions, 1 for training (70%), 1 for validation (20%) and 1 for test (10%). Check that the resulting arrays have the correct shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAVIvFHakAf1",
        "outputId": "2fc7ab43-3d5e-495d-9da5-c562864d507f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (280, 128, 216) \n",
            "X_val shape: (80, 128, 216) \n",
            "X_test shape: (40, 128, 216) \n",
            "y_train shape: (280,) \n",
            "y_val shape: (80,) \n",
            "y_test shape: (40,) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "seed = 42 # We set a seed for reproducibility\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(Xdata, Ydata, train_size=0.7, random_state=seed, stratify=Ydata) #we use stratify to keep the same distribution of classes in the training set\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=seed, stratify=y_temp)  #we use stratify to keep the same distribution of classes in the validation and test sets\n",
        "print('X_train shape: {} \\nX_val shape: {} \\nX_test shape: {} \\ny_train shape: {} \\ny_val shape: {} \\ny_test shape: {} \\n'.format(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCKNh-OsSwYV"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "X_train shape: (280, 128, 216)\n",
        "X_val shape: (80, 128, 216)\n",
        "X_test shape: (40, 128, 216)\n",
        "y_train shape: (280,)\n",
        "y_val shape: (80,)\n",
        "y_test shape: (40,)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9SCglqbdMUW"
      },
      "source": [
        "In the next exercise we will create a time-distributed 1D-CNN to process our dataset. By default, Keras assumes that the last dimension corresponds to the number of channels in our input. Since we are going to use 1D-CNN, each frequency band will be processed as an independent frequency channel. Therefore, we need to reorder the dimensions in our data to move the frequency channels to the last dimension.\n",
        "\n",
        "Use the numpy function \"moveaxis\" to create the data matrices X_train_rs, X_val_rs and X_test_rs, with dimensions (280, 216, 128), (80, 216, 128) and (40, 216, 128):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQEcqqpd5Ri",
        "outputId": "95ac93f0-3fc4-46ed-beeb-fa42c3f0024b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_rs shape: (280, 216, 128) \n",
            "X_val_rs shape: (80, 216, 128) \n",
            "X_test_rs shape: (40, 216, 128)\n"
          ]
        }
      ],
      "source": [
        "X_train_rs = np.moveaxis(X_train, 1, -1)\n",
        "X_val_rs = np.moveaxis(X_val, 1, -1)\n",
        "X_test_rs = np.moveaxis(X_test, 1, -1)\n",
        "\n",
        "print('X_train_rs shape: {} \\nX_val_rs shape: {} \\nX_test_rs shape: {}'.format(X_train_rs.shape, X_val_rs.shape, X_test_rs.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RKqHdABSwYX"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "X_train_rs shape: (280, 216, 128)\n",
        "X_val_rs shape: (80, 216, 128)\n",
        "X_test_rs shape: (40, 216, 128)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLpq0p9Elcc"
      },
      "source": [
        "### **Exercise 7**: Hybrid CNN-RNN\n",
        "\n",
        "In this last exercise we are going to mix our previous time-distributed model with a LSTM layer to create a Hybrid CNN-RNN architecture.\n",
        "\n",
        "Adapt your previous time-distributed model to match the following summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fOKtuDkglYe2"
      },
      "outputs": [],
      "source": [
        "# _________________________________________________________________\n",
        "# Layer (type)                 Output Shape              Param #\n",
        "\n",
        "# Time-Dist Conv1D             (None, None, 120, 16)     160\n",
        "# _________________________________________________________________\n",
        "# Time-Dist MaxPool1D 1D       (None, None, 60, 16)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Dropout (0.5)      (None, None, 60, 16)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Conv1D             (None, None, 58, 16)      784\n",
        "# _________________________________________________________________\n",
        "# Time-Dist MaxPool1D          (None, None, 29, 16)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Dropout (0.5)      (None, None, 29, 16)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Conv1D             (None, None, 27, 32)      1568\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Dropout (0.5)      (None, None, 27, 32)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist MaxPool1D          (None, None, 14, 32)      0\n",
        "# _________________________________________________________________\n",
        "# Time-Dist Flatten            (None, None, 448)         0\n",
        "# _________________________________________________________________\n",
        "# LSTM  (16 neurons)           (None, None, 16)          29760\n",
        "# _________________________________________________________________\n",
        "# Global Av. Pooling 1D        (None, 16)                0\n",
        "# _________________________________________________________________\n",
        "# Dropout (0.35)               (None, 16)                0\n",
        "# _________________________________________________________________\n",
        "# Dense                        (None, 10)                170\n",
        "\n",
        "# Total params: 32,442\n",
        "# Trainable params: 32,442\n",
        "# Non-trainable params: 0\n",
        "# _________________________________________________________________\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time, we assign names to the layers in order to recognise them in the summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "sGgMxslBu7qU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INPUT SHAPE: (None, 128, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_22             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_23             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_24             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_25             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_26             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_27             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_28             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_29             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_30             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_31             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,760</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ SOFTMAX (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_22             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │           \u001b[38;5;34m160\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_23             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_24             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_25             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m784\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_26             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_27             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_28             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_29             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_30             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_31             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │        \u001b[38;5;34m29,760\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ SOFTMAX (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,442</span> (126.73 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,442\u001b[0m (126.73 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,442</span> (126.73 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,442\u001b[0m (126.73 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Create a time distributed model\n",
        "input_shape=(None, X_train_rss.shape[2], X_train_rss.shape[3])\n",
        "print('INPUT SHAPE:',input_shape)\n",
        "model_hyb=tf.keras.models.Sequential()\n",
        "model_hyb.add(tf.keras.Input(shape=input_shape))\n",
        "\n",
        "#1st Conv layer\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(16, 9, activation='relu', name='CONV1')))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2, padding='same', name='MP1')))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "\n",
        "#2nd Conv layer\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(16, 3, activation='relu', name='CONV2')))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2, padding='same', name='MP2')))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "\n",
        "#3rd Conv layer\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, activation='relu', name='CONV3')))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)))\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(2, padding='same', name='MP3'))) #flat the output\n",
        "model_hyb.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten (name='FLATTEN')))\n",
        "\n",
        "#LSTM part\n",
        "model_hyb.add(tf.keras.layers.LSTM(16, name=\"LSTM\", return_sequences=True))\n",
        "model_hyb.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model_hyb.add(tf.keras.layers.Dropout(0.35))\n",
        "\n",
        "#output layer\n",
        "model_hyb.add(tf.keras.layers.Dense(10, activation='softmax', name='SOFTMAX'))\n",
        "model_hyb.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haDJp-HflnI-"
      },
      "source": [
        "Train the network using the same procedure as in previous tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "atsv8EkP5Esd"
      },
      "outputs": [],
      "source": [
        "# CSVLogger\n",
        "csv_logger = CSVLogger('training_1D_CNN_hyb.log', append=False)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "#model checkpoint\n",
        "model_name = 'CNN_1D_model_hyb.h5'\n",
        "model_checkpoint = ModelCheckpoint(model_name, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "#store all these callbacks in a list, Callback list\n",
        "callbacks = [csv_logger, early_stopping, model_checkpoint]\n",
        "\n",
        "# Compile the model\n",
        "learning_rate=0.001\n",
        "batch_size=32\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model_hyb.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1378 - loss: 2.2887\n",
            "Epoch 1: val_accuracy improved from -inf to 0.23750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.1373 - loss: 2.2874 - val_accuracy: 0.2375 - val_loss: 2.1884\n",
            "Epoch 2/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2417 - loss: 2.1585\n",
            "Epoch 2: val_accuracy improved from 0.23750 to 0.28750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.2386 - loss: 2.1581 - val_accuracy: 0.2875 - val_loss: 2.0890\n",
            "Epoch 3/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2396 - loss: 2.0844\n",
            "Epoch 3: val_accuracy improved from 0.28750 to 0.32500, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.2417 - loss: 2.0830 - val_accuracy: 0.3250 - val_loss: 2.0035\n",
            "Epoch 4/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3477 - loss: 1.9551\n",
            "Epoch 4: val_accuracy improved from 0.32500 to 0.38750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.3447 - loss: 1.9577 - val_accuracy: 0.3875 - val_loss: 1.9254\n",
            "Epoch 5/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3893 - loss: 1.8963\n",
            "Epoch 5: val_accuracy improved from 0.38750 to 0.40000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.3893 - loss: 1.8938 - val_accuracy: 0.4000 - val_loss: 1.8509\n",
            "Epoch 6/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4132 - loss: 1.7993\n",
            "Epoch 6: val_accuracy improved from 0.40000 to 0.48750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.4126 - loss: 1.8003 - val_accuracy: 0.4875 - val_loss: 1.8077\n",
            "Epoch 7/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4479 - loss: 1.7243\n",
            "Epoch 7: val_accuracy did not improve from 0.48750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.4442 - loss: 1.7252 - val_accuracy: 0.4500 - val_loss: 1.7640\n",
            "Epoch 8/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4484 - loss: 1.6116\n",
            "Epoch 8: val_accuracy did not improve from 0.48750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.4465 - loss: 1.6168 - val_accuracy: 0.4125 - val_loss: 1.7561\n",
            "Epoch 9/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5194 - loss: 1.5385\n",
            "Epoch 9: val_accuracy did not improve from 0.48750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5200 - loss: 1.5395 - val_accuracy: 0.4500 - val_loss: 1.7364\n",
            "Epoch 10/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5074 - loss: 1.4977\n",
            "Epoch 10: val_accuracy improved from 0.48750 to 0.50000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.5092 - loss: 1.4976 - val_accuracy: 0.5000 - val_loss: 1.6220\n",
            "Epoch 11/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5034 - loss: 1.5460\n",
            "Epoch 11: val_accuracy improved from 0.50000 to 0.55000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5038 - loss: 1.5434 - val_accuracy: 0.5500 - val_loss: 1.5812\n",
            "Epoch 12/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5937 - loss: 1.3540\n",
            "Epoch 12: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5886 - loss: 1.3590 - val_accuracy: 0.5250 - val_loss: 1.5998\n",
            "Epoch 13/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5570 - loss: 1.4583\n",
            "Epoch 13: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.5520 - loss: 1.4643 - val_accuracy: 0.5500 - val_loss: 1.4689\n",
            "Epoch 14/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4519 - loss: 1.5661\n",
            "Epoch 14: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.4531 - loss: 1.5640 - val_accuracy: 0.5375 - val_loss: 1.4635\n",
            "Epoch 15/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5230 - loss: 1.4075\n",
            "Epoch 15: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5225 - loss: 1.4064 - val_accuracy: 0.5250 - val_loss: 1.5395\n",
            "Epoch 16/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5632 - loss: 1.4204\n",
            "Epoch 16: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5658 - loss: 1.4147 - val_accuracy: 0.5500 - val_loss: 1.4789\n",
            "Epoch 17/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5574 - loss: 1.2821\n",
            "Epoch 17: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5570 - loss: 1.2854 - val_accuracy: 0.5250 - val_loss: 1.4422\n",
            "Epoch 18/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5222 - loss: 1.3715\n",
            "Epoch 18: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5236 - loss: 1.3688 - val_accuracy: 0.4875 - val_loss: 1.5483\n",
            "Epoch 19/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5445 - loss: 1.3316\n",
            "Epoch 19: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5469 - loss: 1.3299 - val_accuracy: 0.5375 - val_loss: 1.4997\n",
            "Epoch 20/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5981 - loss: 1.2850\n",
            "Epoch 20: val_accuracy improved from 0.55000 to 0.57500, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.5936 - loss: 1.2929 - val_accuracy: 0.5750 - val_loss: 1.4001\n",
            "Epoch 21/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5268 - loss: 1.3989\n",
            "Epoch 21: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.5302 - loss: 1.3927 - val_accuracy: 0.4875 - val_loss: 1.5560\n",
            "Epoch 22/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5322 - loss: 1.3067\n",
            "Epoch 22: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.5339 - loss: 1.3098 - val_accuracy: 0.4875 - val_loss: 1.5500\n",
            "Epoch 23/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5894 - loss: 1.2819\n",
            "Epoch 23: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5883 - loss: 1.2823 - val_accuracy: 0.5625 - val_loss: 1.3703\n",
            "Epoch 24/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5876 - loss: 1.2084\n",
            "Epoch 24: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5828 - loss: 1.2157 - val_accuracy: 0.5375 - val_loss: 1.4178\n",
            "Epoch 25/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5981 - loss: 1.3089\n",
            "Epoch 25: val_accuracy did not improve from 0.57500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6001 - loss: 1.3025 - val_accuracy: 0.5500 - val_loss: 1.3864\n",
            "Epoch 26/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6158 - loss: 1.1427\n",
            "Epoch 26: val_accuracy improved from 0.57500 to 0.61250, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6164 - loss: 1.1434 - val_accuracy: 0.6125 - val_loss: 1.3226\n",
            "Epoch 27/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5800 - loss: 1.2865\n",
            "Epoch 27: val_accuracy did not improve from 0.61250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5816 - loss: 1.2774 - val_accuracy: 0.6125 - val_loss: 1.2980\n",
            "Epoch 28/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6462 - loss: 1.0813\n",
            "Epoch 28: val_accuracy improved from 0.61250 to 0.62500, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6473 - loss: 1.0843 - val_accuracy: 0.6250 - val_loss: 1.3000\n",
            "Epoch 29/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6274 - loss: 1.1232\n",
            "Epoch 29: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6268 - loss: 1.1282 - val_accuracy: 0.6125 - val_loss: 1.3142\n",
            "Epoch 30/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6130 - loss: 1.1529\n",
            "Epoch 30: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.6138 - loss: 1.1483 - val_accuracy: 0.5625 - val_loss: 1.3538\n",
            "Epoch 31/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7098 - loss: 1.0321\n",
            "Epoch 31: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.7067 - loss: 1.0370 - val_accuracy: 0.6250 - val_loss: 1.2616\n",
            "Epoch 32/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6932 - loss: 1.0258\n",
            "Epoch 32: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6924 - loss: 1.0296 - val_accuracy: 0.6125 - val_loss: 1.2678\n",
            "Epoch 33/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6658 - loss: 1.0659\n",
            "Epoch 33: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.6614 - loss: 1.0711 - val_accuracy: 0.4875 - val_loss: 1.4829\n",
            "Epoch 34/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6664 - loss: 1.1376\n",
            "Epoch 34: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6629 - loss: 1.1381 - val_accuracy: 0.5500 - val_loss: 1.2903\n",
            "Epoch 35/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6658 - loss: 1.0043\n",
            "Epoch 35: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.6635 - loss: 1.0114 - val_accuracy: 0.5875 - val_loss: 1.2601\n",
            "Epoch 36/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6769 - loss: 1.0104\n",
            "Epoch 36: val_accuracy improved from 0.62500 to 0.63750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.6752 - loss: 1.0124 - val_accuracy: 0.6375 - val_loss: 1.2468\n",
            "Epoch 37/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6801 - loss: 1.0225\n",
            "Epoch 37: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6796 - loss: 1.0242 - val_accuracy: 0.6125 - val_loss: 1.2647\n",
            "Epoch 38/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6808 - loss: 0.9726\n",
            "Epoch 38: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.6805 - loss: 0.9725 - val_accuracy: 0.6125 - val_loss: 1.2455\n",
            "Epoch 39/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7044 - loss: 1.0268\n",
            "Epoch 39: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.7054 - loss: 1.0240 - val_accuracy: 0.6125 - val_loss: 1.2120\n",
            "Epoch 40/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7011 - loss: 0.9322\n",
            "Epoch 40: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.7021 - loss: 0.9331 - val_accuracy: 0.6125 - val_loss: 1.1902\n",
            "Epoch 41/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7058 - loss: 0.9722\n",
            "Epoch 41: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.7042 - loss: 0.9753 - val_accuracy: 0.5500 - val_loss: 1.2644\n",
            "Epoch 42/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6622 - loss: 0.9926\n",
            "Epoch 42: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6642 - loss: 0.9912 - val_accuracy: 0.5875 - val_loss: 1.2402\n",
            "Epoch 43/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7089 - loss: 0.9491\n",
            "Epoch 43: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.7084 - loss: 0.9520 - val_accuracy: 0.5875 - val_loss: 1.3496\n",
            "Epoch 44/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7763 - loss: 0.8307\n",
            "Epoch 44: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.7719 - loss: 0.8394 - val_accuracy: 0.6375 - val_loss: 1.1953\n",
            "Epoch 45/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7398 - loss: 0.8964\n",
            "Epoch 45: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.7394 - loss: 0.9006 - val_accuracy: 0.6000 - val_loss: 1.1532\n",
            "Epoch 46/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6676 - loss: 1.0439\n",
            "Epoch 46: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.6687 - loss: 1.0455 - val_accuracy: 0.5750 - val_loss: 1.1842\n",
            "Epoch 47/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6732 - loss: 0.9609\n",
            "Epoch 47: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6766 - loss: 0.9608 - val_accuracy: 0.5750 - val_loss: 1.1975\n",
            "Epoch 48/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6285 - loss: 1.1466\n",
            "Epoch 48: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.6278 - loss: 1.1538 - val_accuracy: 0.6000 - val_loss: 1.2314\n",
            "Epoch 49/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6082 - loss: 1.2191\n",
            "Epoch 49: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6091 - loss: 1.2187 - val_accuracy: 0.5500 - val_loss: 1.3151\n",
            "Epoch 50/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6046 - loss: 1.3244\n",
            "Epoch 50: val_accuracy did not improve from 0.63750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6077 - loss: 1.3093 - val_accuracy: 0.6125 - val_loss: 1.1812\n",
            "Epoch 51/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7213 - loss: 0.9864\n",
            "Epoch 51: val_accuracy improved from 0.63750 to 0.66250, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.7149 - loss: 0.9963 - val_accuracy: 0.6625 - val_loss: 1.1453\n",
            "Epoch 52/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6503 - loss: 1.0765\n",
            "Epoch 52: val_accuracy improved from 0.66250 to 0.68750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.6502 - loss: 1.0769 - val_accuracy: 0.6875 - val_loss: 1.0968\n",
            "Epoch 53/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7128 - loss: 1.0399\n",
            "Epoch 53: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.7119 - loss: 1.0351 - val_accuracy: 0.6500 - val_loss: 1.1447\n",
            "Epoch 54/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6411 - loss: 1.1947\n",
            "Epoch 54: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.6355 - loss: 1.2094 - val_accuracy: 0.6125 - val_loss: 1.2171\n",
            "Epoch 55/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5223 - loss: 1.3542\n",
            "Epoch 55: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.5207 - loss: 1.3491 - val_accuracy: 0.6000 - val_loss: 1.2629\n",
            "Epoch 56/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5846 - loss: 1.2333\n",
            "Epoch 56: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5815 - loss: 1.2386 - val_accuracy: 0.5500 - val_loss: 1.2607\n",
            "Epoch 57/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5909 - loss: 1.1551\n",
            "Epoch 57: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5893 - loss: 1.1582 - val_accuracy: 0.5875 - val_loss: 1.1597\n",
            "Epoch 58/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6218 - loss: 1.0860\n",
            "Epoch 58: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6236 - loss: 1.0870 - val_accuracy: 0.5875 - val_loss: 1.1227\n",
            "Epoch 59/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6776 - loss: 0.9462\n",
            "Epoch 59: val_accuracy did not improve from 0.68750\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6748 - loss: 0.9492 - val_accuracy: 0.6250 - val_loss: 1.1131\n",
            "Epoch 60/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.5520 - loss: 1.1758\n",
            "Epoch 60: val_accuracy improved from 0.68750 to 0.70000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.5543 - loss: 1.1682 - val_accuracy: 0.7000 - val_loss: 1.0672\n",
            "Epoch 61/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6336 - loss: 1.0479\n",
            "Epoch 61: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6342 - loss: 1.0496 - val_accuracy: 0.6125 - val_loss: 1.1733\n",
            "Epoch 62/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6507 - loss: 1.0541\n",
            "Epoch 62: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6499 - loss: 1.0551 - val_accuracy: 0.6250 - val_loss: 1.1265\n",
            "Epoch 63/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6482 - loss: 1.0103\n",
            "Epoch 63: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.6469 - loss: 1.0143 - val_accuracy: 0.5875 - val_loss: 1.1943\n",
            "Epoch 64/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6455 - loss: 1.0386\n",
            "Epoch 64: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6434 - loss: 1.0472 - val_accuracy: 0.6000 - val_loss: 1.1713\n",
            "Epoch 65/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6561 - loss: 1.0444\n",
            "Epoch 65: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6544 - loss: 1.0468 - val_accuracy: 0.6625 - val_loss: 1.0586\n",
            "Epoch 66/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7011 - loss: 0.9772\n",
            "Epoch 66: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.7010 - loss: 0.9738 - val_accuracy: 0.7000 - val_loss: 1.0372\n",
            "Epoch 67/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6968 - loss: 0.9353\n",
            "Epoch 67: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6932 - loss: 0.9388 - val_accuracy: 0.6625 - val_loss: 1.0317\n",
            "Epoch 68/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6991 - loss: 0.8882\n",
            "Epoch 68: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6999 - loss: 0.8915 - val_accuracy: 0.6375 - val_loss: 1.0440\n",
            "Epoch 69/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7333 - loss: 0.8402\n",
            "Epoch 69: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.7314 - loss: 0.8450 - val_accuracy: 0.6750 - val_loss: 1.0168\n",
            "Epoch 70/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6759 - loss: 0.9175\n",
            "Epoch 70: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.6765 - loss: 0.9177 - val_accuracy: 0.7000 - val_loss: 0.9955\n",
            "Epoch 71/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7301 - loss: 0.9248\n",
            "Epoch 71: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7300 - loss: 0.9236 - val_accuracy: 0.7000 - val_loss: 0.9985\n",
            "Epoch 72/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7548 - loss: 0.8778\n",
            "Epoch 72: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7536 - loss: 0.8772 - val_accuracy: 0.6625 - val_loss: 1.0288\n",
            "Epoch 73/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7265 - loss: 0.8367\n",
            "Epoch 73: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.7278 - loss: 0.8360 - val_accuracy: 0.6375 - val_loss: 1.0194\n",
            "Epoch 74/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7749 - loss: 0.7375\n",
            "Epoch 74: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7727 - loss: 0.7454 - val_accuracy: 0.6625 - val_loss: 1.0112\n",
            "Epoch 75/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7432 - loss: 0.8748\n",
            "Epoch 75: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.7446 - loss: 0.8682 - val_accuracy: 0.6750 - val_loss: 0.9913\n",
            "Epoch 76/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7440 - loss: 0.8170\n",
            "Epoch 76: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7446 - loss: 0.8155 - val_accuracy: 0.6625 - val_loss: 0.9992\n",
            "Epoch 77/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7786 - loss: 0.8327\n",
            "Epoch 77: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7775 - loss: 0.8341 - val_accuracy: 0.6500 - val_loss: 1.0382\n",
            "Epoch 78/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7578 - loss: 0.7978\n",
            "Epoch 78: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7567 - loss: 0.7998 - val_accuracy: 0.6375 - val_loss: 1.0586\n",
            "Epoch 79/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7563 - loss: 0.7910\n",
            "Epoch 79: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.7550 - loss: 0.8004 - val_accuracy: 0.6125 - val_loss: 1.1702\n",
            "Epoch 80/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7385 - loss: 0.8964\n",
            "Epoch 80: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7358 - loss: 0.9006 - val_accuracy: 0.5875 - val_loss: 1.2103\n",
            "Epoch 81/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7028 - loss: 1.0240\n",
            "Epoch 81: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7004 - loss: 1.0216 - val_accuracy: 0.6375 - val_loss: 1.0610\n",
            "Epoch 82/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6600 - loss: 0.9695\n",
            "Epoch 82: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6636 - loss: 0.9642 - val_accuracy: 0.6625 - val_loss: 1.0872\n",
            "Epoch 83/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6962 - loss: 0.9484\n",
            "Epoch 83: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.6958 - loss: 0.9441 - val_accuracy: 0.6625 - val_loss: 1.1140\n",
            "Epoch 84/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7304 - loss: 0.8034\n",
            "Epoch 84: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7306 - loss: 0.8040 - val_accuracy: 0.6375 - val_loss: 1.0935\n",
            "Epoch 85/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7443 - loss: 0.8533\n",
            "Epoch 85: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7477 - loss: 0.8448 - val_accuracy: 0.6500 - val_loss: 1.0560\n",
            "Epoch 86/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7836 - loss: 0.7428\n",
            "Epoch 86: val_accuracy improved from 0.70000 to 0.71250, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.7845 - loss: 0.7426 - val_accuracy: 0.7125 - val_loss: 1.0063\n",
            "Epoch 87/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7746 - loss: 0.7670\n",
            "Epoch 87: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.7746 - loss: 0.7649 - val_accuracy: 0.6750 - val_loss: 0.9799\n",
            "Epoch 88/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7484 - loss: 0.7585\n",
            "Epoch 88: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.7507 - loss: 0.7574 - val_accuracy: 0.6625 - val_loss: 1.0011\n",
            "Epoch 89/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7614 - loss: 0.7564\n",
            "Epoch 89: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7617 - loss: 0.7527 - val_accuracy: 0.6500 - val_loss: 1.0069\n",
            "Epoch 90/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7568 - loss: 0.7401\n",
            "Epoch 90: val_accuracy did not improve from 0.71250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7572 - loss: 0.7381 - val_accuracy: 0.7125 - val_loss: 0.9124\n",
            "Epoch 91/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7250 - loss: 0.7586\n",
            "Epoch 91: val_accuracy improved from 0.71250 to 0.72500, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7279 - loss: 0.7536 - val_accuracy: 0.7250 - val_loss: 0.8750\n",
            "Epoch 92/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7897 - loss: 0.7306\n",
            "Epoch 92: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7886 - loss: 0.7330 - val_accuracy: 0.7000 - val_loss: 0.8877\n",
            "Epoch 93/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7684 - loss: 0.7093\n",
            "Epoch 93: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7719 - loss: 0.7076 - val_accuracy: 0.6625 - val_loss: 1.0387\n",
            "Epoch 94/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7426 - loss: 0.7244\n",
            "Epoch 94: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7469 - loss: 0.7207 - val_accuracy: 0.6750 - val_loss: 0.9657\n",
            "Epoch 95/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7979 - loss: 0.6671\n",
            "Epoch 95: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7953 - loss: 0.6706 - val_accuracy: 0.6750 - val_loss: 0.9478\n",
            "Epoch 96/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7804 - loss: 0.7052\n",
            "Epoch 96: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7799 - loss: 0.7061 - val_accuracy: 0.6625 - val_loss: 0.9188\n",
            "Epoch 97/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8042 - loss: 0.6616\n",
            "Epoch 97: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.8023 - loss: 0.6646 - val_accuracy: 0.7125 - val_loss: 0.8669\n",
            "Epoch 98/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7599 - loss: 0.7443\n",
            "Epoch 98: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7614 - loss: 0.7431 - val_accuracy: 0.6875 - val_loss: 0.9293\n",
            "Epoch 99/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7507 - loss: 0.7456\n",
            "Epoch 99: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7528 - loss: 0.7428 - val_accuracy: 0.7000 - val_loss: 0.9168\n",
            "Epoch 100/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8181 - loss: 0.6412\n",
            "Epoch 100: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.8152 - loss: 0.6460 - val_accuracy: 0.6750 - val_loss: 0.9223\n",
            "Epoch 101/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8124 - loss: 0.6389\n",
            "Epoch 101: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8097 - loss: 0.6434 - val_accuracy: 0.6625 - val_loss: 0.9627\n",
            "Epoch 102/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7714 - loss: 0.7002\n",
            "Epoch 102: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 6s/step - accuracy: 0.7728 - loss: 0.7015 - val_accuracy: 0.6750 - val_loss: 0.9554\n",
            "Epoch 103/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8307 - loss: 0.6649\n",
            "Epoch 103: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8287 - loss: 0.6678 - val_accuracy: 0.6875 - val_loss: 0.8930\n",
            "Epoch 104/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7961 - loss: 0.6546\n",
            "Epoch 104: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.7950 - loss: 0.6563 - val_accuracy: 0.6750 - val_loss: 0.9292\n",
            "Epoch 105/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8154 - loss: 0.5856\n",
            "Epoch 105: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8125 - loss: 0.5932 - val_accuracy: 0.5875 - val_loss: 1.1032\n",
            "Epoch 106/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7812 - loss: 0.7352\n",
            "Epoch 106: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7809 - loss: 0.7301 - val_accuracy: 0.6500 - val_loss: 0.9685\n",
            "Epoch 107/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8524 - loss: 0.5677\n",
            "Epoch 107: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8522 - loss: 0.5686 - val_accuracy: 0.6875 - val_loss: 0.9071\n",
            "Epoch 108/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8209 - loss: 0.5910\n",
            "Epoch 108: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8202 - loss: 0.5934 - val_accuracy: 0.7125 - val_loss: 0.8731\n",
            "Epoch 109/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8148 - loss: 0.6152\n",
            "Epoch 109: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8129 - loss: 0.6213 - val_accuracy: 0.7125 - val_loss: 0.8548\n",
            "Epoch 110/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7808 - loss: 0.7441\n",
            "Epoch 110: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7842 - loss: 0.7352 - val_accuracy: 0.6875 - val_loss: 0.9630\n",
            "Epoch 111/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7593 - loss: 0.6780\n",
            "Epoch 111: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7619 - loss: 0.6753 - val_accuracy: 0.6875 - val_loss: 0.9422\n",
            "Epoch 112/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7780 - loss: 0.6834\n",
            "Epoch 112: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7809 - loss: 0.6829 - val_accuracy: 0.6750 - val_loss: 0.9996\n",
            "Epoch 113/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8280 - loss: 0.6236\n",
            "Epoch 113: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8252 - loss: 0.6274 - val_accuracy: 0.6500 - val_loss: 0.9980\n",
            "Epoch 114/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8019 - loss: 0.6513\n",
            "Epoch 114: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8024 - loss: 0.6495 - val_accuracy: 0.6750 - val_loss: 0.8894\n",
            "Epoch 115/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7605 - loss: 0.6885\n",
            "Epoch 115: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7638 - loss: 0.6828 - val_accuracy: 0.6750 - val_loss: 0.8446\n",
            "Epoch 116/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8418 - loss: 0.6276\n",
            "Epoch 116: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8379 - loss: 0.6318 - val_accuracy: 0.7000 - val_loss: 0.8302\n",
            "Epoch 117/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8279 - loss: 0.6332\n",
            "Epoch 117: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8283 - loss: 0.6302 - val_accuracy: 0.7000 - val_loss: 0.7960\n",
            "Epoch 118/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8005 - loss: 0.6131\n",
            "Epoch 118: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8015 - loss: 0.6123 - val_accuracy: 0.6875 - val_loss: 0.8132\n",
            "Epoch 119/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8355 - loss: 0.5736\n",
            "Epoch 119: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8341 - loss: 0.5757 - val_accuracy: 0.6750 - val_loss: 0.8635\n",
            "Epoch 120/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8431 - loss: 0.5279\n",
            "Epoch 120: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8427 - loss: 0.5294 - val_accuracy: 0.6750 - val_loss: 0.8509\n",
            "Epoch 121/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8210 - loss: 0.5407\n",
            "Epoch 121: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8189 - loss: 0.5449 - val_accuracy: 0.6625 - val_loss: 0.8334\n",
            "Epoch 122/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8331 - loss: 0.6393\n",
            "Epoch 122: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8326 - loss: 0.6374 - val_accuracy: 0.6750 - val_loss: 0.8561\n",
            "Epoch 123/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8270 - loss: 0.6072\n",
            "Epoch 123: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8261 - loss: 0.6089 - val_accuracy: 0.7000 - val_loss: 0.8292\n",
            "Epoch 124/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8191 - loss: 0.5710\n",
            "Epoch 124: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8182 - loss: 0.5744 - val_accuracy: 0.6750 - val_loss: 0.8599\n",
            "Epoch 125/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8207 - loss: 0.5830\n",
            "Epoch 125: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8222 - loss: 0.5781 - val_accuracy: 0.6750 - val_loss: 0.8869\n",
            "Epoch 126/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8331 - loss: 0.5885\n",
            "Epoch 126: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8330 - loss: 0.5868 - val_accuracy: 0.6625 - val_loss: 0.9117\n",
            "Epoch 127/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8077 - loss: 0.6299\n",
            "Epoch 127: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8058 - loss: 0.6308 - val_accuracy: 0.7000 - val_loss: 0.9091\n",
            "Epoch 128/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8167 - loss: 0.6116\n",
            "Epoch 128: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8168 - loss: 0.6146 - val_accuracy: 0.7250 - val_loss: 0.8139\n",
            "Epoch 129/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8386 - loss: 0.5625\n",
            "Epoch 129: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8362 - loss: 0.5632 - val_accuracy: 0.7125 - val_loss: 0.8260\n",
            "Epoch 130/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8085 - loss: 0.5869\n",
            "Epoch 130: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8095 - loss: 0.5859 - val_accuracy: 0.6625 - val_loss: 0.8624\n",
            "Epoch 131/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8526 - loss: 0.5049\n",
            "Epoch 131: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8527 - loss: 0.5061 - val_accuracy: 0.6750 - val_loss: 0.8612\n",
            "Epoch 132/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8573 - loss: 0.5306\n",
            "Epoch 132: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8551 - loss: 0.5348 - val_accuracy: 0.6625 - val_loss: 0.8547\n",
            "Epoch 133/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8160 - loss: 0.5852\n",
            "Epoch 133: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8173 - loss: 0.5834 - val_accuracy: 0.6875 - val_loss: 0.8435\n",
            "Epoch 134/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8017 - loss: 0.5855\n",
            "Epoch 134: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8026 - loss: 0.5848 - val_accuracy: 0.6750 - val_loss: 0.8472\n",
            "Epoch 135/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8266 - loss: 0.5987\n",
            "Epoch 135: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8279 - loss: 0.5916 - val_accuracy: 0.7000 - val_loss: 0.7920\n",
            "Epoch 136/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8250 - loss: 0.4944\n",
            "Epoch 136: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8247 - loss: 0.4951 - val_accuracy: 0.6875 - val_loss: 0.7899\n",
            "Epoch 137/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8227 - loss: 0.5691\n",
            "Epoch 137: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8233 - loss: 0.5672 - val_accuracy: 0.7000 - val_loss: 0.7973\n",
            "Epoch 138/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8225 - loss: 0.5521\n",
            "Epoch 138: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8235 - loss: 0.5535 - val_accuracy: 0.6625 - val_loss: 0.8663\n",
            "Epoch 139/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8062 - loss: 0.6183\n",
            "Epoch 139: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8085 - loss: 0.6108 - val_accuracy: 0.6500 - val_loss: 0.8629\n",
            "Epoch 140/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8259 - loss: 0.5355\n",
            "Epoch 140: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8279 - loss: 0.5318 - val_accuracy: 0.6500 - val_loss: 0.8093\n",
            "Epoch 141/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7854 - loss: 0.6054\n",
            "Epoch 141: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.7858 - loss: 0.6020 - val_accuracy: 0.7000 - val_loss: 0.7728\n",
            "Epoch 142/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8697 - loss: 0.4219\n",
            "Epoch 142: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8653 - loss: 0.4301 - val_accuracy: 0.7000 - val_loss: 0.7879\n",
            "Epoch 143/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8097 - loss: 0.5311\n",
            "Epoch 143: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8094 - loss: 0.5367 - val_accuracy: 0.6750 - val_loss: 0.8261\n",
            "Epoch 144/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8395 - loss: 0.4943\n",
            "Epoch 144: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8387 - loss: 0.4974 - val_accuracy: 0.6875 - val_loss: 0.8733\n",
            "Epoch 145/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8710 - loss: 0.4706\n",
            "Epoch 145: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8686 - loss: 0.4782 - val_accuracy: 0.7125 - val_loss: 0.8283\n",
            "Epoch 146/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8020 - loss: 0.6490\n",
            "Epoch 146: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8050 - loss: 0.6388 - val_accuracy: 0.7125 - val_loss: 0.8223\n",
            "Epoch 147/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8011 - loss: 0.6437\n",
            "Epoch 147: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8039 - loss: 0.6374 - val_accuracy: 0.6750 - val_loss: 0.8885\n",
            "Epoch 148/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8216 - loss: 0.6002\n",
            "Epoch 148: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8220 - loss: 0.5995 - val_accuracy: 0.6875 - val_loss: 0.7919\n",
            "Epoch 149/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8135 - loss: 0.6044\n",
            "Epoch 149: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8161 - loss: 0.6002 - val_accuracy: 0.7000 - val_loss: 0.7854\n",
            "Epoch 150/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8365 - loss: 0.4998\n",
            "Epoch 150: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8350 - loss: 0.5025 - val_accuracy: 0.7125 - val_loss: 0.7437\n",
            "Epoch 151/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8209 - loss: 0.5676\n",
            "Epoch 151: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8206 - loss: 0.5669 - val_accuracy: 0.7125 - val_loss: 0.7845\n",
            "Epoch 152/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8022 - loss: 0.5239\n",
            "Epoch 152: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8013 - loss: 0.5323 - val_accuracy: 0.7125 - val_loss: 0.7372\n",
            "Epoch 153/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8558 - loss: 0.5148\n",
            "Epoch 153: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8562 - loss: 0.5151 - val_accuracy: 0.7125 - val_loss: 0.7618\n",
            "Epoch 154/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8797 - loss: 0.4438\n",
            "Epoch 154: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8785 - loss: 0.4460 - val_accuracy: 0.6750 - val_loss: 0.8248\n",
            "Epoch 155/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8488 - loss: 0.5224\n",
            "Epoch 155: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8478 - loss: 0.5231 - val_accuracy: 0.6625 - val_loss: 0.8291\n",
            "Epoch 156/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8566 - loss: 0.5082\n",
            "Epoch 156: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8541 - loss: 0.5120 - val_accuracy: 0.6875 - val_loss: 0.8427\n",
            "Epoch 157/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8210 - loss: 0.5569\n",
            "Epoch 157: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8221 - loss: 0.5576 - val_accuracy: 0.7125 - val_loss: 0.7143\n",
            "Epoch 158/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8718 - loss: 0.4940\n",
            "Epoch 158: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8718 - loss: 0.4947 - val_accuracy: 0.7125 - val_loss: 0.7499\n",
            "Epoch 159/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8221 - loss: 0.5170\n",
            "Epoch 159: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8231 - loss: 0.5183 - val_accuracy: 0.6250 - val_loss: 0.9134\n",
            "Epoch 160/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8647 - loss: 0.5400\n",
            "Epoch 160: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8632 - loss: 0.5415 - val_accuracy: 0.6875 - val_loss: 0.8209\n",
            "Epoch 161/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8066 - loss: 0.5848\n",
            "Epoch 161: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.8110 - loss: 0.5792 - val_accuracy: 0.7250 - val_loss: 0.7535\n",
            "Epoch 162/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8316 - loss: 0.5234\n",
            "Epoch 162: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8306 - loss: 0.5243 - val_accuracy: 0.7250 - val_loss: 0.7471\n",
            "Epoch 163/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8199 - loss: 0.5883\n",
            "Epoch 163: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8201 - loss: 0.5839 - val_accuracy: 0.6875 - val_loss: 0.7973\n",
            "Epoch 164/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8428 - loss: 0.4988\n",
            "Epoch 164: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8435 - loss: 0.4982 - val_accuracy: 0.6500 - val_loss: 0.8378\n",
            "Epoch 165/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8509 - loss: 0.4417\n",
            "Epoch 165: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8508 - loss: 0.4470 - val_accuracy: 0.6875 - val_loss: 0.8314\n",
            "Epoch 166/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8298 - loss: 0.5203\n",
            "Epoch 166: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8304 - loss: 0.5220 - val_accuracy: 0.6500 - val_loss: 0.8714\n",
            "Epoch 167/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8481 - loss: 0.4658\n",
            "Epoch 167: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8475 - loss: 0.4666 - val_accuracy: 0.6875 - val_loss: 0.8048\n",
            "Epoch 168/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8105 - loss: 0.5464\n",
            "Epoch 168: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8138 - loss: 0.5446 - val_accuracy: 0.6750 - val_loss: 0.8567\n",
            "Epoch 169/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8491 - loss: 0.4910\n",
            "Epoch 169: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.8471 - loss: 0.4953 - val_accuracy: 0.6500 - val_loss: 0.8665\n",
            "Epoch 170/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8195 - loss: 0.5661\n",
            "Epoch 170: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8201 - loss: 0.5628 - val_accuracy: 0.6500 - val_loss: 0.8586\n",
            "Epoch 171/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8200 - loss: 0.5291\n",
            "Epoch 171: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8212 - loss: 0.5259 - val_accuracy: 0.6750 - val_loss: 0.8752\n",
            "Epoch 172/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8304 - loss: 0.5012\n",
            "Epoch 172: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.8305 - loss: 0.5069 - val_accuracy: 0.6500 - val_loss: 0.8698\n",
            "Epoch 173/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8420 - loss: 0.4960\n",
            "Epoch 173: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.8410 - loss: 0.4980 - val_accuracy: 0.6375 - val_loss: 0.9155\n",
            "Epoch 174/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8107 - loss: 0.5447\n",
            "Epoch 174: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.8114 - loss: 0.5431 - val_accuracy: 0.6625 - val_loss: 0.9008\n",
            "Epoch 175/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8151 - loss: 0.5146\n",
            "Epoch 175: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.8136 - loss: 0.5220 - val_accuracy: 0.6500 - val_loss: 1.0050\n",
            "Epoch 176/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8215 - loss: 0.5924\n",
            "Epoch 176: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.8215 - loss: 0.5875 - val_accuracy: 0.6625 - val_loss: 0.8822\n",
            "Epoch 177/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8390 - loss: 0.4672\n",
            "Epoch 177: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.8405 - loss: 0.4687 - val_accuracy: 0.6875 - val_loss: 0.8123\n",
            "Epoch 178/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8119 - loss: 0.5123\n",
            "Epoch 178: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8128 - loss: 0.5140 - val_accuracy: 0.6750 - val_loss: 0.8154\n",
            "Epoch 179/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8486 - loss: 0.4635\n",
            "Epoch 179: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8506 - loss: 0.4642 - val_accuracy: 0.6500 - val_loss: 0.8711\n",
            "Epoch 180/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8646 - loss: 0.4694\n",
            "Epoch 180: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8638 - loss: 0.4697 - val_accuracy: 0.6500 - val_loss: 0.8327\n",
            "Epoch 181/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8505 - loss: 0.4610\n",
            "Epoch 181: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8512 - loss: 0.4600 - val_accuracy: 0.6625 - val_loss: 0.8262\n",
            "Epoch 182/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8548 - loss: 0.5703\n",
            "Epoch 182: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8539 - loss: 0.5748 - val_accuracy: 0.6750 - val_loss: 0.9028\n",
            "Epoch 183/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8700 - loss: 0.5900\n",
            "Epoch 183: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8683 - loss: 0.5835 - val_accuracy: 0.6750 - val_loss: 0.8473\n",
            "Epoch 184/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7994 - loss: 0.5480\n",
            "Epoch 184: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8016 - loss: 0.5484 - val_accuracy: 0.6625 - val_loss: 0.9217\n",
            "Epoch 185/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8649 - loss: 0.4858\n",
            "Epoch 185: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8616 - loss: 0.4908 - val_accuracy: 0.6750 - val_loss: 0.8589\n",
            "Epoch 186/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8796 - loss: 0.4367\n",
            "Epoch 186: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8787 - loss: 0.4378 - val_accuracy: 0.6250 - val_loss: 0.8958\n",
            "Epoch 187/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8735 - loss: 0.4816\n",
            "Epoch 187: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step - accuracy: 0.8730 - loss: 0.4810 - val_accuracy: 0.6250 - val_loss: 0.9117\n",
            "Epoch 188/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8608 - loss: 0.4939\n",
            "Epoch 188: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8608 - loss: 0.4920 - val_accuracy: 0.6500 - val_loss: 0.8389\n",
            "Epoch 189/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8410 - loss: 0.5337\n",
            "Epoch 189: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8437 - loss: 0.5284 - val_accuracy: 0.6750 - val_loss: 0.7938\n",
            "Epoch 190/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8454 - loss: 0.4754\n",
            "Epoch 190: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8473 - loss: 0.4726 - val_accuracy: 0.6500 - val_loss: 0.8253\n",
            "Epoch 191/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8775 - loss: 0.4196\n",
            "Epoch 191: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8776 - loss: 0.4196 - val_accuracy: 0.6625 - val_loss: 0.8284\n",
            "Epoch 192/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8617 - loss: 0.4541\n",
            "Epoch 192: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8623 - loss: 0.4521 - val_accuracy: 0.6875 - val_loss: 0.7879\n",
            "Epoch 193/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8305 - loss: 0.5022\n",
            "Epoch 193: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.8321 - loss: 0.4956 - val_accuracy: 0.7250 - val_loss: 0.7844\n",
            "Epoch 194/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8578 - loss: 0.4771\n",
            "Epoch 194: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8588 - loss: 0.4761 - val_accuracy: 0.7000 - val_loss: 0.8296\n",
            "Epoch 195/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7989 - loss: 0.4876\n",
            "Epoch 195: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8018 - loss: 0.4828 - val_accuracy: 0.6750 - val_loss: 0.8520\n",
            "Epoch 196/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9114 - loss: 0.3805\n",
            "Epoch 196: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.9096 - loss: 0.3831 - val_accuracy: 0.6875 - val_loss: 0.8435\n",
            "Epoch 197/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8810 - loss: 0.4225\n",
            "Epoch 197: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8811 - loss: 0.4230 - val_accuracy: 0.6875 - val_loss: 0.8235\n",
            "Epoch 198/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8831 - loss: 0.4057\n",
            "Epoch 198: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8834 - loss: 0.4061 - val_accuracy: 0.6500 - val_loss: 0.8754\n",
            "Epoch 199/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8882 - loss: 0.4105\n",
            "Epoch 199: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8861 - loss: 0.4129 - val_accuracy: 0.6500 - val_loss: 0.8679\n",
            "Epoch 200/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8487 - loss: 0.4596\n",
            "Epoch 200: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8503 - loss: 0.4562 - val_accuracy: 0.6875 - val_loss: 0.7957\n",
            "Epoch 201/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8695 - loss: 0.4177\n",
            "Epoch 201: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8715 - loss: 0.4147 - val_accuracy: 0.7125 - val_loss: 0.7565\n",
            "Epoch 202/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8611 - loss: 0.4499\n",
            "Epoch 202: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6s/step - accuracy: 0.8611 - loss: 0.4475 - val_accuracy: 0.7125 - val_loss: 0.7202\n",
            "Epoch 203/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8707 - loss: 0.4466\n",
            "Epoch 203: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.8722 - loss: 0.4437 - val_accuracy: 0.7250 - val_loss: 0.7258\n",
            "Epoch 204/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8874 - loss: 0.3692\n",
            "Epoch 204: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.8883 - loss: 0.3710 - val_accuracy: 0.7250 - val_loss: 0.7402\n",
            "Epoch 205/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8595 - loss: 0.4766\n",
            "Epoch 205: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.8593 - loss: 0.4717 - val_accuracy: 0.7250 - val_loss: 0.7274\n",
            "Epoch 206/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8733 - loss: 0.3699\n",
            "Epoch 206: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.8745 - loss: 0.3717 - val_accuracy: 0.7125 - val_loss: 0.7250\n",
            "Epoch 207/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8674 - loss: 0.4180\n",
            "Epoch 207: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.8693 - loss: 0.4147 - val_accuracy: 0.6875 - val_loss: 0.7389\n",
            "Epoch 208/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8789 - loss: 0.4110\n",
            "Epoch 208: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8796 - loss: 0.4089 - val_accuracy: 0.7000 - val_loss: 0.7352\n",
            "Epoch 209/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8977 - loss: 0.3440\n",
            "Epoch 209: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8962 - loss: 0.3477 - val_accuracy: 0.6875 - val_loss: 0.7597\n",
            "Epoch 210/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8433 - loss: 0.4352\n",
            "Epoch 210: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8468 - loss: 0.4298 - val_accuracy: 0.6875 - val_loss: 0.7694\n",
            "Epoch 211/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8887 - loss: 0.3947\n",
            "Epoch 211: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8888 - loss: 0.3922 - val_accuracy: 0.6875 - val_loss: 0.7430\n",
            "Epoch 212/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8416 - loss: 0.4527\n",
            "Epoch 212: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.8435 - loss: 0.4486 - val_accuracy: 0.6875 - val_loss: 0.7513\n",
            "Epoch 213/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8797 - loss: 0.3922\n",
            "Epoch 213: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.8810 - loss: 0.3900 - val_accuracy: 0.6875 - val_loss: 0.7396\n",
            "Epoch 214/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8669 - loss: 0.3855\n",
            "Epoch 214: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.8666 - loss: 0.3887 - val_accuracy: 0.6875 - val_loss: 0.7416\n",
            "Epoch 215/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8898 - loss: 0.3906\n",
            "Epoch 215: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8894 - loss: 0.3882 - val_accuracy: 0.7125 - val_loss: 0.7638\n",
            "Epoch 216/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8830 - loss: 0.4007\n",
            "Epoch 216: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8790 - loss: 0.4048 - val_accuracy: 0.7125 - val_loss: 0.7197\n",
            "Epoch 217/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8957 - loss: 0.4017\n",
            "Epoch 217: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8947 - loss: 0.4032 - val_accuracy: 0.7125 - val_loss: 0.6993\n",
            "Epoch 218/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8683 - loss: 0.4530\n",
            "Epoch 218: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8697 - loss: 0.4468 - val_accuracy: 0.7250 - val_loss: 0.7223\n",
            "Epoch 219/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8439 - loss: 0.3898\n",
            "Epoch 219: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8434 - loss: 0.3920 - val_accuracy: 0.7125 - val_loss: 0.7747\n",
            "Epoch 220/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8917 - loss: 0.3731\n",
            "Epoch 220: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8915 - loss: 0.3728 - val_accuracy: 0.6750 - val_loss: 0.7755\n",
            "Epoch 221/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8998 - loss: 0.3869\n",
            "Epoch 221: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8973 - loss: 0.3865 - val_accuracy: 0.6750 - val_loss: 0.7514\n",
            "Epoch 222/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8533 - loss: 0.4055\n",
            "Epoch 222: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8548 - loss: 0.4047 - val_accuracy: 0.6625 - val_loss: 0.8548\n",
            "Epoch 223/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8788 - loss: 0.4346\n",
            "Epoch 223: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8802 - loss: 0.4315 - val_accuracy: 0.7000 - val_loss: 0.8548\n",
            "Epoch 224/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8457 - loss: 0.4139\n",
            "Epoch 224: val_accuracy did not improve from 0.72500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8483 - loss: 0.4120 - val_accuracy: 0.7250 - val_loss: 0.8605\n",
            "Epoch 225/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9078 - loss: 0.3414\n",
            "Epoch 225: val_accuracy improved from 0.72500 to 0.73750, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9081 - loss: 0.3431 - val_accuracy: 0.7375 - val_loss: 0.8354\n",
            "Epoch 226/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8823 - loss: 0.3323\n",
            "Epoch 226: val_accuracy improved from 0.73750 to 0.75000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8809 - loss: 0.3337 - val_accuracy: 0.7500 - val_loss: 0.8257\n",
            "Epoch 227/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9306 - loss: 0.3473\n",
            "Epoch 227: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9286 - loss: 0.3482 - val_accuracy: 0.7375 - val_loss: 0.8181\n",
            "Epoch 228/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8962 - loss: 0.3874\n",
            "Epoch 228: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8969 - loss: 0.3868 - val_accuracy: 0.7375 - val_loss: 0.7801\n",
            "Epoch 229/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9083 - loss: 0.3675\n",
            "Epoch 229: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9074 - loss: 0.3699 - val_accuracy: 0.7500 - val_loss: 0.7436\n",
            "Epoch 230/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8810 - loss: 0.3846\n",
            "Epoch 230: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.8807 - loss: 0.3853 - val_accuracy: 0.7250 - val_loss: 0.7585\n",
            "Epoch 231/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8888 - loss: 0.3810\n",
            "Epoch 231: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8863 - loss: 0.3892 - val_accuracy: 0.5250 - val_loss: 1.6134\n",
            "Epoch 232/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6976 - loss: 0.9260\n",
            "Epoch 232: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.6946 - loss: 0.9373 - val_accuracy: 0.4625 - val_loss: 1.6989\n",
            "Epoch 233/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7146 - loss: 0.8727\n",
            "Epoch 233: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.7149 - loss: 0.8671 - val_accuracy: 0.6000 - val_loss: 0.9408\n",
            "Epoch 234/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7340 - loss: 0.7931\n",
            "Epoch 234: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.7346 - loss: 0.7901 - val_accuracy: 0.6625 - val_loss: 0.8973\n",
            "Epoch 235/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8263 - loss: 0.5613\n",
            "Epoch 235: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8244 - loss: 0.5633 - val_accuracy: 0.6500 - val_loss: 0.9223\n",
            "Epoch 236/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7813 - loss: 0.6336\n",
            "Epoch 236: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.7817 - loss: 0.6334 - val_accuracy: 0.6625 - val_loss: 0.8909\n",
            "Epoch 237/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7960 - loss: 0.5546\n",
            "Epoch 237: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.7964 - loss: 0.5562 - val_accuracy: 0.6750 - val_loss: 0.8339\n",
            "Epoch 238/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8323 - loss: 0.5263\n",
            "Epoch 238: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8316 - loss: 0.5292 - val_accuracy: 0.6500 - val_loss: 0.8336\n",
            "Epoch 239/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8010 - loss: 0.5911\n",
            "Epoch 239: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8055 - loss: 0.5861 - val_accuracy: 0.6500 - val_loss: 0.8088\n",
            "Epoch 240/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8524 - loss: 0.4848\n",
            "Epoch 240: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8522 - loss: 0.4855 - val_accuracy: 0.6625 - val_loss: 0.8045\n",
            "Epoch 241/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8419 - loss: 0.4707\n",
            "Epoch 241: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8413 - loss: 0.4713 - val_accuracy: 0.6500 - val_loss: 0.7686\n",
            "Epoch 242/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8380 - loss: 0.5137\n",
            "Epoch 242: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8384 - loss: 0.5109 - val_accuracy: 0.6625 - val_loss: 0.7684\n",
            "Epoch 243/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8653 - loss: 0.4556\n",
            "Epoch 243: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8637 - loss: 0.4573 - val_accuracy: 0.6625 - val_loss: 0.7821\n",
            "Epoch 244/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8430 - loss: 0.4655\n",
            "Epoch 244: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8458 - loss: 0.4634 - val_accuracy: 0.6500 - val_loss: 0.7981\n",
            "Epoch 245/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8776 - loss: 0.3670\n",
            "Epoch 245: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8784 - loss: 0.3685 - val_accuracy: 0.6625 - val_loss: 0.7770\n",
            "Epoch 246/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8912 - loss: 0.4163\n",
            "Epoch 246: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8892 - loss: 0.4189 - val_accuracy: 0.6875 - val_loss: 0.7575\n",
            "Epoch 247/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8649 - loss: 0.4194\n",
            "Epoch 247: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8637 - loss: 0.4238 - val_accuracy: 0.6500 - val_loss: 0.8280\n",
            "Epoch 248/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8356 - loss: 0.4866\n",
            "Epoch 248: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8388 - loss: 0.4826 - val_accuracy: 0.6625 - val_loss: 0.7550\n",
            "Epoch 249/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8460 - loss: 0.4157\n",
            "Epoch 249: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8464 - loss: 0.4173 - val_accuracy: 0.6625 - val_loss: 0.7705\n",
            "Epoch 250/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8639 - loss: 0.4151\n",
            "Epoch 250: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8632 - loss: 0.4155 - val_accuracy: 0.6625 - val_loss: 0.7417\n",
            "Epoch 251/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8824 - loss: 0.4049\n",
            "Epoch 251: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8835 - loss: 0.4025 - val_accuracy: 0.6750 - val_loss: 0.7400\n",
            "Epoch 252/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8989 - loss: 0.3553\n",
            "Epoch 252: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8969 - loss: 0.3597 - val_accuracy: 0.6500 - val_loss: 0.7856\n",
            "Epoch 253/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9086 - loss: 0.3684\n",
            "Epoch 253: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9063 - loss: 0.3727 - val_accuracy: 0.6625 - val_loss: 0.7813\n",
            "Epoch 254/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8436 - loss: 0.4306\n",
            "Epoch 254: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8424 - loss: 0.4325 - val_accuracy: 0.6875 - val_loss: 0.7688\n",
            "Epoch 255/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8437 - loss: 0.4025\n",
            "Epoch 255: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8432 - loss: 0.4060 - val_accuracy: 0.6875 - val_loss: 0.7755\n",
            "Epoch 256/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8483 - loss: 0.4440\n",
            "Epoch 256: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8478 - loss: 0.4443 - val_accuracy: 0.7000 - val_loss: 0.7698\n",
            "Epoch 257/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8433 - loss: 0.4214\n",
            "Epoch 257: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8432 - loss: 0.4238 - val_accuracy: 0.7000 - val_loss: 0.7988\n",
            "Epoch 258/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8914 - loss: 0.3816\n",
            "Epoch 258: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8922 - loss: 0.3800 - val_accuracy: 0.7000 - val_loss: 0.7689\n",
            "Epoch 259/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8550 - loss: 0.4287\n",
            "Epoch 259: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8566 - loss: 0.4248 - val_accuracy: 0.7000 - val_loss: 0.8033\n",
            "Epoch 260/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8534 - loss: 0.3990\n",
            "Epoch 260: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.8545 - loss: 0.4002 - val_accuracy: 0.6875 - val_loss: 0.7776\n",
            "Epoch 261/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8800 - loss: 0.3634\n",
            "Epoch 261: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8784 - loss: 0.3667 - val_accuracy: 0.6875 - val_loss: 0.7732\n",
            "Epoch 262/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8927 - loss: 0.3654\n",
            "Epoch 262: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8941 - loss: 0.3629 - val_accuracy: 0.6875 - val_loss: 0.7678\n",
            "Epoch 263/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8835 - loss: 0.3793\n",
            "Epoch 263: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8840 - loss: 0.3796 - val_accuracy: 0.7125 - val_loss: 0.7491\n",
            "Epoch 264/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9023 - loss: 0.3579\n",
            "Epoch 264: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9002 - loss: 0.3588 - val_accuracy: 0.7125 - val_loss: 0.7729\n",
            "Epoch 265/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8646 - loss: 0.3997\n",
            "Epoch 265: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8663 - loss: 0.3973 - val_accuracy: 0.7250 - val_loss: 0.7512\n",
            "Epoch 266/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8969 - loss: 0.3361\n",
            "Epoch 266: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8976 - loss: 0.3350 - val_accuracy: 0.7125 - val_loss: 0.7585\n",
            "Epoch 267/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8941 - loss: 0.3713\n",
            "Epoch 267: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8940 - loss: 0.3705 - val_accuracy: 0.7125 - val_loss: 0.7395\n",
            "Epoch 268/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9040 - loss: 0.3319\n",
            "Epoch 268: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9036 - loss: 0.3340 - val_accuracy: 0.7250 - val_loss: 0.7307\n",
            "Epoch 269/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8898 - loss: 0.3391\n",
            "Epoch 269: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8898 - loss: 0.3418 - val_accuracy: 0.7000 - val_loss: 0.7241\n",
            "Epoch 270/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9066 - loss: 0.3395\n",
            "Epoch 270: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9070 - loss: 0.3393 - val_accuracy: 0.6875 - val_loss: 0.7586\n",
            "Epoch 271/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8630 - loss: 0.3663\n",
            "Epoch 271: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8638 - loss: 0.3659 - val_accuracy: 0.6875 - val_loss: 0.7358\n",
            "Epoch 272/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8827 - loss: 0.3614\n",
            "Epoch 272: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8819 - loss: 0.3626 - val_accuracy: 0.7000 - val_loss: 0.7085\n",
            "Epoch 273/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8725 - loss: 0.3332\n",
            "Epoch 273: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8724 - loss: 0.3347 - val_accuracy: 0.7125 - val_loss: 0.7155\n",
            "Epoch 274/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9015 - loss: 0.3151\n",
            "Epoch 274: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9010 - loss: 0.3186 - val_accuracy: 0.7000 - val_loss: 0.7327\n",
            "Epoch 275/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8784 - loss: 0.3889\n",
            "Epoch 275: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8791 - loss: 0.3853 - val_accuracy: 0.6875 - val_loss: 0.7900\n",
            "Epoch 276/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9042 - loss: 0.3697\n",
            "Epoch 276: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9034 - loss: 0.3710 - val_accuracy: 0.7000 - val_loss: 0.7977\n",
            "Epoch 277/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8892 - loss: 0.3573\n",
            "Epoch 277: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8896 - loss: 0.3570 - val_accuracy: 0.7000 - val_loss: 0.7868\n",
            "Epoch 278/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8793 - loss: 0.3558\n",
            "Epoch 278: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8792 - loss: 0.3575 - val_accuracy: 0.7250 - val_loss: 0.7817\n",
            "Epoch 279/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8798 - loss: 0.3420\n",
            "Epoch 279: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8800 - loss: 0.3436 - val_accuracy: 0.7375 - val_loss: 0.7678\n",
            "Epoch 280/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8551 - loss: 0.3737\n",
            "Epoch 280: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8582 - loss: 0.3714 - val_accuracy: 0.7250 - val_loss: 0.7648\n",
            "Epoch 281/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9081 - loss: 0.3168\n",
            "Epoch 281: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9080 - loss: 0.3173 - val_accuracy: 0.7125 - val_loss: 0.7584\n",
            "Epoch 282/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8942 - loss: 0.3120\n",
            "Epoch 282: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8948 - loss: 0.3134 - val_accuracy: 0.7500 - val_loss: 0.6922\n",
            "Epoch 283/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8848 - loss: 0.4472\n",
            "Epoch 283: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8839 - loss: 0.4515 - val_accuracy: 0.7000 - val_loss: 0.8892\n",
            "Epoch 284/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8674 - loss: 0.4694\n",
            "Epoch 284: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8678 - loss: 0.4715 - val_accuracy: 0.6875 - val_loss: 0.8984\n",
            "Epoch 285/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8566 - loss: 0.4906\n",
            "Epoch 285: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8552 - loss: 0.4946 - val_accuracy: 0.6625 - val_loss: 0.9284\n",
            "Epoch 286/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8290 - loss: 0.4914\n",
            "Epoch 286: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 8s/step - accuracy: 0.8297 - loss: 0.4902 - val_accuracy: 0.6750 - val_loss: 0.8166\n",
            "Epoch 287/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8609 - loss: 0.4329\n",
            "Epoch 287: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.8595 - loss: 0.4351 - val_accuracy: 0.7125 - val_loss: 0.7196\n",
            "Epoch 288/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8851 - loss: 0.3466\n",
            "Epoch 288: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8841 - loss: 0.3489 - val_accuracy: 0.7250 - val_loss: 0.7413\n",
            "Epoch 289/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8859 - loss: 0.4039\n",
            "Epoch 289: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8862 - loss: 0.4016 - val_accuracy: 0.7250 - val_loss: 0.7493\n",
            "Epoch 290/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9261 - loss: 0.3105\n",
            "Epoch 290: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9239 - loss: 0.3113 - val_accuracy: 0.7375 - val_loss: 0.7269\n",
            "Epoch 291/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8977 - loss: 0.3077\n",
            "Epoch 291: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8983 - loss: 0.3101 - val_accuracy: 0.7250 - val_loss: 0.7251\n",
            "Epoch 292/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8698 - loss: 0.3543\n",
            "Epoch 292: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8714 - loss: 0.3506 - val_accuracy: 0.6875 - val_loss: 0.7298\n",
            "Epoch 293/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9058 - loss: 0.2990\n",
            "Epoch 293: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9063 - loss: 0.3004 - val_accuracy: 0.7000 - val_loss: 0.7265\n",
            "Epoch 294/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9121 - loss: 0.2982\n",
            "Epoch 294: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - accuracy: 0.9116 - loss: 0.2997 - val_accuracy: 0.6875 - val_loss: 0.7303\n",
            "Epoch 295/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9422 - loss: 0.2810\n",
            "Epoch 295: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7s/step - accuracy: 0.9391 - loss: 0.2871 - val_accuracy: 0.7250 - val_loss: 0.7309\n",
            "Epoch 296/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8801 - loss: 0.2980\n",
            "Epoch 296: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8803 - loss: 0.2997 - val_accuracy: 0.7250 - val_loss: 0.7707\n",
            "Epoch 297/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9425 - loss: 0.3048\n",
            "Epoch 297: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.9418 - loss: 0.3034 - val_accuracy: 0.7250 - val_loss: 0.7645\n",
            "Epoch 298/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9200 - loss: 0.2864\n",
            "Epoch 298: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9184 - loss: 0.2899 - val_accuracy: 0.7125 - val_loss: 0.8186\n",
            "Epoch 299/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9011 - loss: 0.3603\n",
            "Epoch 299: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9003 - loss: 0.3639 - val_accuracy: 0.7250 - val_loss: 0.7716\n",
            "Epoch 300/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9415 - loss: 0.2782\n",
            "Epoch 300: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9399 - loss: 0.2819 - val_accuracy: 0.7375 - val_loss: 0.7639\n",
            "Epoch 301/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9189 - loss: 0.2841\n",
            "Epoch 301: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9191 - loss: 0.2862 - val_accuracy: 0.7250 - val_loss: 0.7437\n",
            "Epoch 302/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9009 - loss: 0.3123\n",
            "Epoch 302: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9012 - loss: 0.3130 - val_accuracy: 0.7250 - val_loss: 0.7360\n",
            "Epoch 303/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9145 - loss: 0.3251\n",
            "Epoch 303: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9130 - loss: 0.3262 - val_accuracy: 0.7000 - val_loss: 0.7776\n",
            "Epoch 304/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9288 - loss: 0.2902\n",
            "Epoch 304: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9281 - loss: 0.2908 - val_accuracy: 0.6875 - val_loss: 0.7433\n",
            "Epoch 305/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9105 - loss: 0.3047\n",
            "Epoch 305: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9109 - loss: 0.3050 - val_accuracy: 0.7375 - val_loss: 0.7023\n",
            "Epoch 306/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9349 - loss: 0.2615\n",
            "Epoch 306: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9336 - loss: 0.2649 - val_accuracy: 0.7125 - val_loss: 0.6972\n",
            "Epoch 307/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9280 - loss: 0.2575\n",
            "Epoch 307: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9270 - loss: 0.2591 - val_accuracy: 0.6625 - val_loss: 0.7722\n",
            "Epoch 308/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8983 - loss: 0.3410\n",
            "Epoch 308: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8988 - loss: 0.3400 - val_accuracy: 0.6875 - val_loss: 0.7723\n",
            "Epoch 309/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8654 - loss: 0.3353\n",
            "Epoch 309: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8670 - loss: 0.3358 - val_accuracy: 0.6625 - val_loss: 0.7904\n",
            "Epoch 310/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8986 - loss: 0.3062\n",
            "Epoch 310: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8984 - loss: 0.3038 - val_accuracy: 0.6750 - val_loss: 0.7383\n",
            "Epoch 311/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9176 - loss: 0.3005\n",
            "Epoch 311: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9162 - loss: 0.3018 - val_accuracy: 0.7125 - val_loss: 0.7275\n",
            "Epoch 312/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9122 - loss: 0.3230\n",
            "Epoch 312: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9121 - loss: 0.3232 - val_accuracy: 0.6875 - val_loss: 0.7113\n",
            "Epoch 313/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8978 - loss: 0.2994\n",
            "Epoch 313: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8962 - loss: 0.3043 - val_accuracy: 0.7000 - val_loss: 0.7802\n",
            "Epoch 314/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9096 - loss: 0.3124\n",
            "Epoch 314: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9101 - loss: 0.3146 - val_accuracy: 0.7125 - val_loss: 0.7671\n",
            "Epoch 315/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8933 - loss: 0.3182\n",
            "Epoch 315: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8936 - loss: 0.3173 - val_accuracy: 0.7125 - val_loss: 0.7774\n",
            "Epoch 316/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9415 - loss: 0.2576\n",
            "Epoch 316: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9384 - loss: 0.2622 - val_accuracy: 0.7000 - val_loss: 0.7786\n",
            "Epoch 317/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9252 - loss: 0.2456\n",
            "Epoch 317: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9259 - loss: 0.2468 - val_accuracy: 0.7125 - val_loss: 0.8186\n",
            "Epoch 318/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9335 - loss: 0.2622\n",
            "Epoch 318: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9295 - loss: 0.2679 - val_accuracy: 0.7250 - val_loss: 0.8272\n",
            "Epoch 319/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9149 - loss: 0.2916\n",
            "Epoch 319: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9141 - loss: 0.2915 - val_accuracy: 0.7000 - val_loss: 0.8048\n",
            "Epoch 320/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9176 - loss: 0.2870\n",
            "Epoch 320: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9176 - loss: 0.2853 - val_accuracy: 0.6750 - val_loss: 0.8900\n",
            "Epoch 321/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9227 - loss: 0.2615\n",
            "Epoch 321: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9233 - loss: 0.2611 - val_accuracy: 0.6875 - val_loss: 0.8553\n",
            "Epoch 322/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9185 - loss: 0.2659\n",
            "Epoch 322: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9177 - loss: 0.2676 - val_accuracy: 0.6875 - val_loss: 0.8428\n",
            "Epoch 323/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9046 - loss: 0.2970\n",
            "Epoch 323: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9063 - loss: 0.2982 - val_accuracy: 0.6875 - val_loss: 0.8510\n",
            "Epoch 324/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9095 - loss: 0.3232\n",
            "Epoch 324: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9114 - loss: 0.3191 - val_accuracy: 0.7000 - val_loss: 0.8340\n",
            "Epoch 325/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8949 - loss: 0.2969\n",
            "Epoch 325: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8968 - loss: 0.2942 - val_accuracy: 0.7250 - val_loss: 0.8180\n",
            "Epoch 326/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9153 - loss: 0.2806\n",
            "Epoch 326: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9135 - loss: 0.2827 - val_accuracy: 0.7125 - val_loss: 0.7972\n",
            "Epoch 327/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9438 - loss: 0.2686\n",
            "Epoch 327: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9422 - loss: 0.2693 - val_accuracy: 0.7250 - val_loss: 0.8483\n",
            "Epoch 328/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9051 - loss: 0.2781\n",
            "Epoch 328: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9035 - loss: 0.2818 - val_accuracy: 0.7500 - val_loss: 0.8697\n",
            "Epoch 329/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9451 - loss: 0.2621\n",
            "Epoch 329: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9427 - loss: 0.2633 - val_accuracy: 0.7500 - val_loss: 0.8503\n",
            "Epoch 330/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9078 - loss: 0.2587\n",
            "Epoch 330: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9084 - loss: 0.2587 - val_accuracy: 0.7250 - val_loss: 0.8376\n",
            "Epoch 331/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9018 - loss: 0.2672\n",
            "Epoch 331: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8998 - loss: 0.2695 - val_accuracy: 0.7125 - val_loss: 0.8355\n",
            "Epoch 332/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9012 - loss: 0.2872\n",
            "Epoch 332: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9021 - loss: 0.2848 - val_accuracy: 0.7250 - val_loss: 0.7856\n",
            "Epoch 333/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9060 - loss: 0.2840\n",
            "Epoch 333: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9054 - loss: 0.2842 - val_accuracy: 0.7125 - val_loss: 0.8777\n",
            "Epoch 334/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9135 - loss: 0.2712\n",
            "Epoch 334: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9140 - loss: 0.2709 - val_accuracy: 0.7000 - val_loss: 0.8928\n",
            "Epoch 335/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9558 - loss: 0.2234\n",
            "Epoch 335: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9545 - loss: 0.2247 - val_accuracy: 0.7000 - val_loss: 0.8066\n",
            "Epoch 336/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9182 - loss: 0.2319\n",
            "Epoch 336: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9174 - loss: 0.2337 - val_accuracy: 0.7500 - val_loss: 0.7865\n",
            "Epoch 337/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9207 - loss: 0.2416\n",
            "Epoch 337: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9214 - loss: 0.2418 - val_accuracy: 0.7375 - val_loss: 0.8028\n",
            "Epoch 338/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9090 - loss: 0.2750\n",
            "Epoch 338: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9099 - loss: 0.2741 - val_accuracy: 0.7250 - val_loss: 0.8110\n",
            "Epoch 339/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9485 - loss: 0.1946\n",
            "Epoch 339: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9476 - loss: 0.1959 - val_accuracy: 0.7250 - val_loss: 0.8031\n",
            "Epoch 340/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9383 - loss: 0.2202\n",
            "Epoch 340: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9388 - loss: 0.2197 - val_accuracy: 0.7125 - val_loss: 0.7996\n",
            "Epoch 341/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8778 - loss: 0.2750\n",
            "Epoch 341: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - accuracy: 0.8796 - loss: 0.2739 - val_accuracy: 0.7000 - val_loss: 0.8075\n",
            "Epoch 342/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9163 - loss: 0.3048\n",
            "Epoch 342: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - accuracy: 0.9168 - loss: 0.3028 - val_accuracy: 0.7000 - val_loss: 0.8215\n",
            "Epoch 343/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9243 - loss: 0.2410\n",
            "Epoch 343: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 8s/step - accuracy: 0.9236 - loss: 0.2414 - val_accuracy: 0.7250 - val_loss: 0.8173\n",
            "Epoch 344/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9467 - loss: 0.2220\n",
            "Epoch 344: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9452 - loss: 0.2238 - val_accuracy: 0.7125 - val_loss: 0.8798\n",
            "Epoch 345/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9509 - loss: 0.1854\n",
            "Epoch 345: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9515 - loss: 0.1864 - val_accuracy: 0.7125 - val_loss: 0.8892\n",
            "Epoch 346/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9318 - loss: 0.2515\n",
            "Epoch 346: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9308 - loss: 0.2522 - val_accuracy: 0.7125 - val_loss: 0.8818\n",
            "Epoch 347/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9456 - loss: 0.1988\n",
            "Epoch 347: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9450 - loss: 0.2013 - val_accuracy: 0.7500 - val_loss: 0.7887\n",
            "Epoch 348/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9256 - loss: 0.2171\n",
            "Epoch 348: val_accuracy improved from 0.75000 to 0.76250, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9259 - loss: 0.2197 - val_accuracy: 0.7625 - val_loss: 0.7544\n",
            "Epoch 349/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9552 - loss: 0.2011\n",
            "Epoch 349: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9536 - loss: 0.2038 - val_accuracy: 0.7375 - val_loss: 0.7810\n",
            "Epoch 350/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9113 - loss: 0.2630\n",
            "Epoch 350: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9127 - loss: 0.2634 - val_accuracy: 0.7125 - val_loss: 0.8512\n",
            "Epoch 351/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9260 - loss: 0.2638\n",
            "Epoch 351: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9255 - loss: 0.2666 - val_accuracy: 0.7250 - val_loss: 0.8516\n",
            "Epoch 352/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9177 - loss: 0.2258\n",
            "Epoch 352: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9174 - loss: 0.2287 - val_accuracy: 0.7500 - val_loss: 0.8711\n",
            "Epoch 353/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8929 - loss: 0.2726\n",
            "Epoch 353: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8943 - loss: 0.2730 - val_accuracy: 0.7125 - val_loss: 0.8606\n",
            "Epoch 354/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9402 - loss: 0.2258\n",
            "Epoch 354: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9394 - loss: 0.2269 - val_accuracy: 0.7125 - val_loss: 0.8528\n",
            "Epoch 355/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9441 - loss: 0.2193\n",
            "Epoch 355: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9426 - loss: 0.2228 - val_accuracy: 0.7000 - val_loss: 0.8170\n",
            "Epoch 356/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9249 - loss: 0.2252\n",
            "Epoch 356: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9246 - loss: 0.2286 - val_accuracy: 0.7125 - val_loss: 0.8261\n",
            "Epoch 357/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9430 - loss: 0.1970\n",
            "Epoch 357: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9415 - loss: 0.1990 - val_accuracy: 0.7375 - val_loss: 0.8599\n",
            "Epoch 358/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9204 - loss: 0.2465\n",
            "Epoch 358: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9212 - loss: 0.2462 - val_accuracy: 0.7375 - val_loss: 0.8725\n",
            "Epoch 359/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9473 - loss: 0.1985\n",
            "Epoch 359: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9469 - loss: 0.1998 - val_accuracy: 0.7375 - val_loss: 0.8658\n",
            "Epoch 360/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8899 - loss: 0.2647\n",
            "Epoch 360: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.8930 - loss: 0.2608 - val_accuracy: 0.7125 - val_loss: 0.7507\n",
            "Epoch 361/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9533 - loss: 0.1756\n",
            "Epoch 361: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9519 - loss: 0.1787 - val_accuracy: 0.7125 - val_loss: 0.7675\n",
            "Epoch 362/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9283 - loss: 0.1993\n",
            "Epoch 362: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9291 - loss: 0.2028 - val_accuracy: 0.7000 - val_loss: 0.8117\n",
            "Epoch 363/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9327 - loss: 0.2454\n",
            "Epoch 363: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9337 - loss: 0.2459 - val_accuracy: 0.6750 - val_loss: 0.9132\n",
            "Epoch 364/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8942 - loss: 0.3173\n",
            "Epoch 364: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.8951 - loss: 0.3155 - val_accuracy: 0.6750 - val_loss: 0.9050\n",
            "Epoch 365/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9051 - loss: 0.2733\n",
            "Epoch 365: val_accuracy did not improve from 0.76250\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9060 - loss: 0.2756 - val_accuracy: 0.7000 - val_loss: 0.8066\n",
            "Epoch 366/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9307 - loss: 0.2261\n",
            "Epoch 366: val_accuracy improved from 0.76250 to 0.77500, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9284 - loss: 0.2315 - val_accuracy: 0.7750 - val_loss: 0.6699\n",
            "Epoch 367/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9590 - loss: 0.2256\n",
            "Epoch 367: val_accuracy improved from 0.77500 to 0.80000, saving model to CNN_1D_model_hyb.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9588 - loss: 0.2252 - val_accuracy: 0.8000 - val_loss: 0.6013\n",
            "Epoch 368/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9288 - loss: 0.2617\n",
            "Epoch 368: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9281 - loss: 0.2614 - val_accuracy: 0.7625 - val_loss: 0.6364\n",
            "Epoch 369/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9525 - loss: 0.2268\n",
            "Epoch 369: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9526 - loss: 0.2254 - val_accuracy: 0.7375 - val_loss: 0.7200\n",
            "Epoch 370/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9295 - loss: 0.2582\n",
            "Epoch 370: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9305 - loss: 0.2567 - val_accuracy: 0.7375 - val_loss: 0.7955\n",
            "Epoch 371/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9494 - loss: 0.1999\n",
            "Epoch 371: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9502 - loss: 0.2002 - val_accuracy: 0.7375 - val_loss: 0.7695\n",
            "Epoch 372/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9324 - loss: 0.2257\n",
            "Epoch 372: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9323 - loss: 0.2266 - val_accuracy: 0.7375 - val_loss: 0.8026\n",
            "Epoch 373/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9361 - loss: 0.2149\n",
            "Epoch 373: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9367 - loss: 0.2127 - val_accuracy: 0.7375 - val_loss: 0.8136\n",
            "Epoch 374/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9320 - loss: 0.2550\n",
            "Epoch 374: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9331 - loss: 0.2517 - val_accuracy: 0.7250 - val_loss: 0.8311\n",
            "Epoch 375/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9333 - loss: 0.2116\n",
            "Epoch 375: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9346 - loss: 0.2105 - val_accuracy: 0.7000 - val_loss: 0.8592\n",
            "Epoch 376/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9535 - loss: 0.2349\n",
            "Epoch 376: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9525 - loss: 0.2361 - val_accuracy: 0.7125 - val_loss: 0.8350\n",
            "Epoch 377/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9134 - loss: 0.2443\n",
            "Epoch 377: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9142 - loss: 0.2460 - val_accuracy: 0.7000 - val_loss: 0.8366\n",
            "Epoch 378/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9471 - loss: 0.1945\n",
            "Epoch 378: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9478 - loss: 0.1950 - val_accuracy: 0.7125 - val_loss: 0.8429\n",
            "Epoch 379/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9602 - loss: 0.1924\n",
            "Epoch 379: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9584 - loss: 0.1946 - val_accuracy: 0.7375 - val_loss: 0.8202\n",
            "Epoch 380/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9313 - loss: 0.2262\n",
            "Epoch 380: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.9303 - loss: 0.2278 - val_accuracy: 0.7500 - val_loss: 0.7715\n",
            "Epoch 381/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9266 - loss: 0.2277\n",
            "Epoch 381: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.9260 - loss: 0.2281 - val_accuracy: 0.7375 - val_loss: 0.7798\n",
            "Epoch 382/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9500 - loss: 0.1705\n",
            "Epoch 382: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.9493 - loss: 0.1722 - val_accuracy: 0.7125 - val_loss: 0.8185\n",
            "Epoch 383/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9348 - loss: 0.2129\n",
            "Epoch 383: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6s/step - accuracy: 0.9349 - loss: 0.2126 - val_accuracy: 0.7375 - val_loss: 0.8233\n",
            "Epoch 384/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9595 - loss: 0.1691\n",
            "Epoch 384: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.9578 - loss: 0.1722 - val_accuracy: 0.7000 - val_loss: 0.8283\n",
            "Epoch 385/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9548 - loss: 0.2127\n",
            "Epoch 385: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9543 - loss: 0.2113 - val_accuracy: 0.7250 - val_loss: 0.7833\n",
            "Epoch 386/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9320 - loss: 0.2244\n",
            "Epoch 386: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7s/step - accuracy: 0.9327 - loss: 0.2228 - val_accuracy: 0.7125 - val_loss: 0.8809\n",
            "Epoch 387/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9523 - loss: 0.1842\n",
            "Epoch 387: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7s/step - accuracy: 0.9514 - loss: 0.1867 - val_accuracy: 0.6875 - val_loss: 0.8993\n",
            "Epoch 388/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9442 - loss: 0.2052\n",
            "Epoch 388: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.9451 - loss: 0.2040 - val_accuracy: 0.6500 - val_loss: 0.9545\n",
            "Epoch 389/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9574 - loss: 0.1881\n",
            "Epoch 389: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.9563 - loss: 0.1907 - val_accuracy: 0.6625 - val_loss: 0.9289\n",
            "Epoch 390/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9321 - loss: 0.1970\n",
            "Epoch 390: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.9346 - loss: 0.1930 - val_accuracy: 0.7250 - val_loss: 0.8269\n",
            "Epoch 391/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9411 - loss: 0.2205\n",
            "Epoch 391: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9430 - loss: 0.2177 - val_accuracy: 0.7375 - val_loss: 0.8097\n",
            "Epoch 392/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9222 - loss: 0.2598\n",
            "Epoch 392: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9221 - loss: 0.2570 - val_accuracy: 0.7500 - val_loss: 0.8577\n",
            "Epoch 393/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9396 - loss: 0.2391\n",
            "Epoch 393: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9392 - loss: 0.2398 - val_accuracy: 0.7500 - val_loss: 0.8404\n",
            "Epoch 394/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9188 - loss: 0.2333\n",
            "Epoch 394: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9180 - loss: 0.2379 - val_accuracy: 0.7375 - val_loss: 0.9199\n",
            "Epoch 395/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9579 - loss: 0.1954\n",
            "Epoch 395: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9568 - loss: 0.1964 - val_accuracy: 0.7500 - val_loss: 0.8194\n",
            "Epoch 396/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9565 - loss: 0.1743\n",
            "Epoch 396: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9558 - loss: 0.1757 - val_accuracy: 0.7250 - val_loss: 0.8943\n",
            "Epoch 397/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9455 - loss: 0.2213\n",
            "Epoch 397: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 7s/step - accuracy: 0.9452 - loss: 0.2216 - val_accuracy: 0.7250 - val_loss: 0.8460\n",
            "Epoch 398/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9209 - loss: 0.2445\n",
            "Epoch 398: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9213 - loss: 0.2421 - val_accuracy: 0.7375 - val_loss: 0.8250\n",
            "Epoch 399/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9194 - loss: 0.2257\n",
            "Epoch 399: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9214 - loss: 0.2229 - val_accuracy: 0.7500 - val_loss: 0.8227\n",
            "Epoch 400/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9392 - loss: 0.1988\n",
            "Epoch 400: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 8s/step - accuracy: 0.9399 - loss: 0.1991 - val_accuracy: 0.7500 - val_loss: 0.8073\n",
            "Epoch 401/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9284 - loss: 0.2418\n",
            "Epoch 401: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9302 - loss: 0.2385 - val_accuracy: 0.7500 - val_loss: 0.7958\n",
            "Epoch 402/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9579 - loss: 0.1920\n",
            "Epoch 402: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9586 - loss: 0.1897 - val_accuracy: 0.7500 - val_loss: 0.8540\n",
            "Epoch 403/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9393 - loss: 0.2285\n",
            "Epoch 403: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9400 - loss: 0.2249 - val_accuracy: 0.7625 - val_loss: 0.8476\n",
            "Epoch 404/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9501 - loss: 0.1909\n",
            "Epoch 404: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9504 - loss: 0.1947 - val_accuracy: 0.7500 - val_loss: 0.8926\n",
            "Epoch 405/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9440 - loss: 0.2221\n",
            "Epoch 405: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9446 - loss: 0.2210 - val_accuracy: 0.7250 - val_loss: 0.9526\n",
            "Epoch 406/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9038 - loss: 0.3147\n",
            "Epoch 406: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9055 - loss: 0.3096 - val_accuracy: 0.7000 - val_loss: 1.0355\n",
            "Epoch 407/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9559 - loss: 0.2052\n",
            "Epoch 407: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9557 - loss: 0.2071 - val_accuracy: 0.7375 - val_loss: 0.9091\n",
            "Epoch 408/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9310 - loss: 0.1919\n",
            "Epoch 408: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9318 - loss: 0.1907 - val_accuracy: 0.7500 - val_loss: 0.9159\n",
            "Epoch 409/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9303 - loss: 0.2402\n",
            "Epoch 409: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9309 - loss: 0.2382 - val_accuracy: 0.7375 - val_loss: 0.9508\n",
            "Epoch 410/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9741 - loss: 0.1682\n",
            "Epoch 410: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9728 - loss: 0.1705 - val_accuracy: 0.7375 - val_loss: 0.8313\n",
            "Epoch 411/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9553 - loss: 0.1747\n",
            "Epoch 411: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 8s/step - accuracy: 0.9559 - loss: 0.1759 - val_accuracy: 0.7625 - val_loss: 0.8078\n",
            "Epoch 412/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9588 - loss: 0.1530\n",
            "Epoch 412: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7s/step - accuracy: 0.9579 - loss: 0.1547 - val_accuracy: 0.7000 - val_loss: 0.9406\n",
            "Epoch 413/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9250 - loss: 0.2291\n",
            "Epoch 413: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9261 - loss: 0.2267 - val_accuracy: 0.7625 - val_loss: 0.8412\n",
            "Epoch 414/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9655 - loss: 0.1685\n",
            "Epoch 414: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9643 - loss: 0.1692 - val_accuracy: 0.7625 - val_loss: 0.8898\n",
            "Epoch 415/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9372 - loss: 0.1955\n",
            "Epoch 415: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9384 - loss: 0.1947 - val_accuracy: 0.7500 - val_loss: 0.9083\n",
            "Epoch 416/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9641 - loss: 0.2368\n",
            "Epoch 416: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9644 - loss: 0.2342 - val_accuracy: 0.7750 - val_loss: 0.8122\n",
            "Epoch 417/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9628 - loss: 0.2176\n",
            "Epoch 417: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9629 - loss: 0.2134 - val_accuracy: 0.7625 - val_loss: 0.7954\n",
            "Epoch 418/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9665 - loss: 0.1474\n",
            "Epoch 418: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9659 - loss: 0.1492 - val_accuracy: 0.7375 - val_loss: 0.8095\n",
            "Epoch 419/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9464 - loss: 0.1877\n",
            "Epoch 419: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9464 - loss: 0.1887 - val_accuracy: 0.7500 - val_loss: 0.7862\n",
            "Epoch 420/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9274 - loss: 0.1931\n",
            "Epoch 420: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9293 - loss: 0.1923 - val_accuracy: 0.7375 - val_loss: 0.8595\n",
            "Epoch 421/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9590 - loss: 0.1622\n",
            "Epoch 421: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9588 - loss: 0.1638 - val_accuracy: 0.7375 - val_loss: 0.8639\n",
            "Epoch 422/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9465 - loss: 0.1882\n",
            "Epoch 422: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9440 - loss: 0.1929 - val_accuracy: 0.7375 - val_loss: 0.9189\n",
            "Epoch 423/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9374 - loss: 0.1952\n",
            "Epoch 423: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9372 - loss: 0.1955 - val_accuracy: 0.6875 - val_loss: 0.9754\n",
            "Epoch 424/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8994 - loss: 0.2931\n",
            "Epoch 424: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8983 - loss: 0.2988 - val_accuracy: 0.6625 - val_loss: 1.1251\n",
            "Epoch 425/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9337 - loss: 0.2556\n",
            "Epoch 425: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9328 - loss: 0.2543 - val_accuracy: 0.7500 - val_loss: 0.9453\n",
            "Epoch 426/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9445 - loss: 0.1955\n",
            "Epoch 426: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9443 - loss: 0.1960 - val_accuracy: 0.7250 - val_loss: 1.0155\n",
            "Epoch 427/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9134 - loss: 0.2065\n",
            "Epoch 427: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9159 - loss: 0.2053 - val_accuracy: 0.7750 - val_loss: 0.8691\n",
            "Epoch 428/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8966 - loss: 0.3402\n",
            "Epoch 428: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.8994 - loss: 0.3330 - val_accuracy: 0.7625 - val_loss: 0.9010\n",
            "Epoch 429/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9053 - loss: 0.2624\n",
            "Epoch 429: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9080 - loss: 0.2596 - val_accuracy: 0.7250 - val_loss: 0.9571\n",
            "Epoch 430/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9115 - loss: 0.2569\n",
            "Epoch 430: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9132 - loss: 0.2536 - val_accuracy: 0.7250 - val_loss: 0.9293\n",
            "Epoch 431/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9596 - loss: 0.1664\n",
            "Epoch 431: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9572 - loss: 0.1701 - val_accuracy: 0.7375 - val_loss: 0.9009\n",
            "Epoch 432/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9409 - loss: 0.2205\n",
            "Epoch 432: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9418 - loss: 0.2193 - val_accuracy: 0.7375 - val_loss: 0.9513\n",
            "Epoch 433/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9373 - loss: 0.1978\n",
            "Epoch 433: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9378 - loss: 0.1978 - val_accuracy: 0.7375 - val_loss: 0.8198\n",
            "Epoch 434/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9507 - loss: 0.1788\n",
            "Epoch 434: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9478 - loss: 0.1820 - val_accuracy: 0.7125 - val_loss: 0.8749\n",
            "Epoch 435/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8927 - loss: 0.3435\n",
            "Epoch 435: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.8942 - loss: 0.3406 - val_accuracy: 0.7125 - val_loss: 0.8949\n",
            "Epoch 436/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9672 - loss: 0.1539\n",
            "Epoch 436: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9666 - loss: 0.1565 - val_accuracy: 0.7000 - val_loss: 0.9008\n",
            "Epoch 437/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9435 - loss: 0.1894\n",
            "Epoch 437: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9434 - loss: 0.1895 - val_accuracy: 0.7000 - val_loss: 0.9027\n",
            "Epoch 438/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9678 - loss: 0.1762\n",
            "Epoch 438: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9678 - loss: 0.1752 - val_accuracy: 0.7000 - val_loss: 0.8967\n",
            "Epoch 439/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9795 - loss: 0.1366\n",
            "Epoch 439: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9790 - loss: 0.1365 - val_accuracy: 0.7000 - val_loss: 0.9147\n",
            "Epoch 440/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9646 - loss: 0.1800\n",
            "Epoch 440: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9646 - loss: 0.1792 - val_accuracy: 0.7000 - val_loss: 0.9492\n",
            "Epoch 441/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9530 - loss: 0.1794\n",
            "Epoch 441: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9527 - loss: 0.1811 - val_accuracy: 0.7125 - val_loss: 0.8956\n",
            "Epoch 442/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9629 - loss: 0.1451\n",
            "Epoch 442: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9627 - loss: 0.1448 - val_accuracy: 0.7250 - val_loss: 0.8923\n",
            "Epoch 443/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9577 - loss: 0.1873\n",
            "Epoch 443: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9558 - loss: 0.1906 - val_accuracy: 0.7375 - val_loss: 0.8923\n",
            "Epoch 444/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9559 - loss: 0.1475\n",
            "Epoch 444: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9571 - loss: 0.1468 - val_accuracy: 0.7375 - val_loss: 0.9354\n",
            "Epoch 445/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9549 - loss: 0.1841\n",
            "Epoch 445: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9555 - loss: 0.1838 - val_accuracy: 0.7250 - val_loss: 0.9486\n",
            "Epoch 446/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9637 - loss: 0.1359\n",
            "Epoch 446: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9623 - loss: 0.1384 - val_accuracy: 0.7000 - val_loss: 0.9867\n",
            "Epoch 447/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9659 - loss: 0.1425\n",
            "Epoch 447: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9657 - loss: 0.1426 - val_accuracy: 0.7250 - val_loss: 0.9397\n",
            "Epoch 448/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9483 - loss: 0.1776\n",
            "Epoch 448: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9471 - loss: 0.1799 - val_accuracy: 0.7500 - val_loss: 0.8949\n",
            "Epoch 449/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9683 - loss: 0.1745\n",
            "Epoch 449: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9675 - loss: 0.1744 - val_accuracy: 0.7375 - val_loss: 0.9343\n",
            "Epoch 450/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9570 - loss: 0.1563\n",
            "Epoch 450: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7s/step - accuracy: 0.9559 - loss: 0.1582 - val_accuracy: 0.7375 - val_loss: 0.9436\n",
            "Epoch 451/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9487 - loss: 0.1736\n",
            "Epoch 451: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9471 - loss: 0.1771 - val_accuracy: 0.7375 - val_loss: 0.8893\n",
            "Epoch 452/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9316 - loss: 0.2300\n",
            "Epoch 452: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 7s/step - accuracy: 0.9317 - loss: 0.2277 - val_accuracy: 0.7375 - val_loss: 0.9906\n",
            "Epoch 453/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9446 - loss: 0.1657\n",
            "Epoch 453: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9437 - loss: 0.1686 - val_accuracy: 0.7250 - val_loss: 0.9630\n",
            "Epoch 454/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9593 - loss: 0.1734\n",
            "Epoch 454: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9580 - loss: 0.1742 - val_accuracy: 0.7250 - val_loss: 0.9504\n",
            "Epoch 455/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9580 - loss: 0.1506\n",
            "Epoch 455: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 7s/step - accuracy: 0.9575 - loss: 0.1513 - val_accuracy: 0.7250 - val_loss: 0.9588\n",
            "Epoch 456/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9648 - loss: 0.1498\n",
            "Epoch 456: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9655 - loss: 0.1497 - val_accuracy: 0.7125 - val_loss: 0.9589\n",
            "Epoch 457/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9373 - loss: 0.1717\n",
            "Epoch 457: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9368 - loss: 0.1742 - val_accuracy: 0.7375 - val_loss: 0.9645\n",
            "Epoch 458/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9457 - loss: 0.1866\n",
            "Epoch 458: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9454 - loss: 0.1857 - val_accuracy: 0.7500 - val_loss: 0.8634\n",
            "Epoch 459/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9553 - loss: 0.1482\n",
            "Epoch 459: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9551 - loss: 0.1504 - val_accuracy: 0.7250 - val_loss: 0.9074\n",
            "Epoch 460/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9404 - loss: 0.1776\n",
            "Epoch 460: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9403 - loss: 0.1799 - val_accuracy: 0.7375 - val_loss: 0.8295\n",
            "Epoch 461/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9481 - loss: 0.1435\n",
            "Epoch 461: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9483 - loss: 0.1450 - val_accuracy: 0.7125 - val_loss: 0.9479\n",
            "Epoch 462/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9472 - loss: 0.1779\n",
            "Epoch 462: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9486 - loss: 0.1771 - val_accuracy: 0.6875 - val_loss: 0.9280\n",
            "Epoch 463/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9626 - loss: 0.1575\n",
            "Epoch 463: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9613 - loss: 0.1604 - val_accuracy: 0.7125 - val_loss: 0.9017\n",
            "Epoch 464/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9502 - loss: 0.1725\n",
            "Epoch 464: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.9501 - loss: 0.1730 - val_accuracy: 0.7125 - val_loss: 0.9725\n",
            "Epoch 465/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9386 - loss: 0.2583\n",
            "Epoch 465: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9369 - loss: 0.2626 - val_accuracy: 0.7500 - val_loss: 0.9386\n",
            "Epoch 466/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9267 - loss: 0.2381\n",
            "Epoch 466: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9287 - loss: 0.2361 - val_accuracy: 0.7250 - val_loss: 0.9590\n",
            "Epoch 467/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9594 - loss: 0.1844\n",
            "Epoch 467: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7s/step - accuracy: 0.9592 - loss: 0.1823 - val_accuracy: 0.7125 - val_loss: 1.0135\n"
          ]
        }
      ],
      "source": [
        "# Fitting\n",
        "history_hyb = model_hyb.fit(X_train_rss, y_train, batch_size=batch_size, epochs=1000, validation_data=(X_val_rss, y_val), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMkqqjiplt8N"
      },
      "source": [
        "Plot the training history and evaluate the model using the optimal weights (from early stopping).\n",
        "\n",
        "NOTE: For the evaluation, compare the validation/test loss and accuracy, display the confusion matrices and show the classification reports.\n",
        "Discuss your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YSmF4hvQZBW"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best validation accuracy:  0.800000011920929\n",
            "Epoch for which we get the best validation accuracy:  366\n",
            "Test loss: 0.9050397872924805\n",
            "Test accuracy: 0.7250000238418579\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "log_df_hyb = pd.read_csv('training_1D_CNN_hyb.log')\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(log_df_hyb['epoch'], log_df_hyb['accuracy'], label='Train')\n",
        "plt.plot(log_df_hyb['epoch'], log_df_hyb['val_accuracy'], label='Validation')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(log_df_hyb['epoch'], log_df_hyb['loss'], label='Train')\n",
        "plt.plot(log_df_hyb['epoch'], log_df_hyb['val_loss'], label='Validation')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#best validation accuracy\n",
        "best_acc = np.max(history_hyb.history['val_accuracy'])\n",
        "best_acc_epoch = np.argmax(history_hyb.history['val_accuracy'])\n",
        "print('Best validation accuracy: ', best_acc)\n",
        "print('Epoch for which we get the best validation accuracy: ', best_acc_epoch)\n",
        "\n",
        "model_hyb.load_weights('CNN_1D_model_hyb.h5')\n",
        "[loss_test, acc_test] = model_hyb.evaluate(X_test_rss, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss_test}\")\n",
        "print(f\"Test accuracy: {acc_test}\")\n",
        "\n",
        "possible_classes = np.arange(0, 10)\n",
        "\n",
        "pred_val = model_hyb.predict(X_val_rss)\n",
        "pred_test = model_hyb.predict(X_test_rss)\n",
        "\n",
        "pred_val_classes = np.argmax(pred_val, axis=1)\n",
        "pred_test_classes = np.argmax(pred_test, axis=1)\n",
        "\n",
        "# Confusion matrix computation\n",
        "cm_val = confusion_matrix(y_val, pred_val_classes)\n",
        "cm_test = confusion_matrix(y_test, pred_test_classes)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "disp_val = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=possible_classes)\n",
        "disp_val.plot(cmap=plt.cm.Blues, ax=axes[0], values_format='d')\n",
        "axes[0].set_title('Confusion Matrix - Validation Set')\n",
        "\n",
        "\n",
        "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=possible_classes)\n",
        "disp_test.plot(cmap=plt.cm.Blues, ax=axes[1], values_format='d')\n",
        "axes[1].set_title('Confusion Matrix - Test Set')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Validation set --------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88         8\n",
            "           1       0.89      1.00      0.94         8\n",
            "           2       0.67      0.50      0.57         8\n",
            "           3       1.00      0.88      0.93         8\n",
            "           4       1.00      0.50      0.67         8\n",
            "           5       0.89      1.00      0.94         8\n",
            "           6       1.00      0.50      0.67         8\n",
            "           7       0.73      1.00      0.84         8\n",
            "           8       0.57      1.00      0.73         8\n",
            "           9       0.75      0.75      0.75         8\n",
            "\n",
            "    accuracy                           0.80        80\n",
            "   macro avg       0.84      0.80      0.79        80\n",
            "weighted avg       0.84      0.80      0.79        80\n",
            "\n",
            "---------------- Test set ------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         4\n",
            "           1       0.75      0.75      0.75         4\n",
            "           2       0.75      0.75      0.75         4\n",
            "           3       0.50      0.75      0.60         4\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      0.75      0.86         4\n",
            "           7       0.80      1.00      0.89         4\n",
            "           8       0.60      0.75      0.67         4\n",
            "           9       0.67      0.50      0.57         4\n",
            "\n",
            "    accuracy                           0.72        40\n",
            "   macro avg       0.69      0.72      0.70        40\n",
            "weighted avg       0.69      0.72      0.70        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('------------ Validation set --------------')\n",
        "print(classification_report(y_val, pred_val_classes))\n",
        "\n",
        "print('---------------- Test set ------------------')\n",
        "print(classification_report(y_test, pred_test_classes))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MAECap",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
